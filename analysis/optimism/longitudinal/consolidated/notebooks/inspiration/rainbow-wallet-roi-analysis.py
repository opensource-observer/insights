import marimo

__generated_with = "0.19.2"
app = marimo.App()


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    # Measuring Rainbow Wallet's impact on OP Mainnet
    <small>Owner: <span style="background-color: #f0f0f0; padding: 2px 4px; border-radius: 3px;">Optimism</span> · Last Updated: <span style="background-color: #f0f0f0; padding: 2px 4px; border-radius: 3px;">2025-11-17</span></small>
    """)
    return


@app.cell(hide_code=True)
def _(
    headline_actity_vs_incentives,
    headline_distribution_summary,
    headline_rainbow_user_churn,
    headline_retention_comparison,
    headline_user_ltv,
    mo,
):
    _context = f"""
    - Agreement Terms: https://gov.optimism.io/t/review-gf-phase-1-proposal-optimism-rainbow/3564
    - Proposed Success Metric: *RevShare From Swaps Using Rainbow's Router Contract*

    Measurement Approach:

    1. Calculate the direct revshare contributions generated by swaps in the Rainbow wallet
    2. Isolate the subset of addresses that were onboarded to the Superchain via the in-wallet swaps (i.e., new addresses)
    3. Measure the LTV for the new addresses, which constitutes the indirect revshare constributions
    4. Combine the direct and indirect revshare contributions to estimate the payback period for the grant
    """
    _placeholder_headline = "placeholder"
    _insights = f"""
    1. {headline_distribution_summary}.
    2. {headline_user_ltv}.
    3. {headline_actity_vs_incentives}.
    4. {headline_rainbow_user_churn}.
    5. {headline_retention_comparison}.
    """

    mo.accordion({
        "Context": _context,
        "Key Insights": _insights,
        "Data Sources": """
        - [Superchain Data (c/o Goldsky)](https://bit.ly/superchain-public-data) - Source of raw transaction and traces data
        - [Chainlink DevHub](https://docs.chain.link/data-feeds/using-data-feeds) - Oracle addresses on OP Mainnet    
        - [OSS Directory](https://github.com/opensource-observer/oss-directory) - OSO's public project and address registry
        - [OSO API](https://docs.opensource.observer/docs/get-started/python) - Data and metrics pipeline
        """
    })    
    return


@app.cell(hide_code=True)
def _(pd):
    _csv_path = "https://raw.githubusercontent.com/opensource-observer/insights/refs/heads/main/analysis/optimism/dune/rainbow_op_rewards.csv"
    df_rewards_raw = pd.read_csv(_csv_path)
    address_list = list(sorted(df_rewards_raw['address'].unique()))

    df_cac = df_rewards_raw.groupby('address', as_index=False, observed=False)['op_reward'].sum()
    df_cac.sort_values(by='op_reward', inplace=True)

    df_funding_monthly = df_rewards_raw.copy()
    df_funding_monthly['bucket_month'] = pd.to_datetime(df_funding_monthly['dt']).dt.to_period('M').dt.to_timestamp()
    df_funding_monthly = (
        df_funding_monthly
        .groupby('bucket_month', as_index=False)['op_reward']
        .sum()
    )
    df_funding_monthly['rewards_distributed'] = df_funding_monthly['op_reward'].cumsum()
    return address_list, df_cac, df_funding_monthly


@app.cell(hide_code=True)
def _(address_list, df_cac, df_funding_monthly, mo, pd, px):
    _total_users = len(address_list)
    _total_op = df_cac['op_reward'].sum()
    _median_op = df_cac['op_reward'].median()

    _bins = [0, 1, 10, 100, 1000, float('inf')]
    _labels = ["<1", "1-10", "10–100", "100–1000", "1000+"]
    df_cac['bucket'] = pd.cut(df_cac['op_reward'], bins=_bins, labels=_labels, right=False)

    _df_dist = df_cac.groupby('bucket', as_index=False, observed=False)['op_reward'].count()
    _df_dist.columns = ['bucket', 'count']

    _fig_dist = px.bar(
        _df_dist,
        x='bucket',
        y='count',
        text='count',
        template="plotly_white"
    )
    _fig_dist.update_traces(textposition='outside')
    _fig_dist.update_layout(
        xaxis_title='Award Range (OP)',
        yaxis_title='User Count',
        margin=dict(l=40, r=10, t=40, b=40)
    )



    _first_date = df_funding_monthly['bucket_month'].min().strftime('%b %Y')
    _last_date = df_funding_monthly['bucket_month'].max().strftime('%b %Y')

    _fig_time = px.area(
        data_frame=df_funding_monthly,
        x='bucket_month',
        y='rewards_distributed',
        line_shape='hvh',
        template="plotly_white"
    )
    _fig_time.update_layout(
        xaxis_title='Date',
        yaxis_title='Cumulative OP Distributed',
        margin=dict(l=40, r=10, t=40, b=40)
    )

    headline_distribution_summary = (
        f"From {_first_date} to {_last_date}, Rainbow distributed {_total_op/1000:,.0f}K OP in incentives "
        f"to {_total_users:,.0f} unique addresses on OP Mainnet"
    )

    mo.vstack([
        mo.md(f"## {headline_distribution_summary}"),
        mo.md(
            f"The median reward amount was {_median_op:,.2f} OP. "
            "Most users received their funds in a single disbursement."
        ),
        mo.hstack(
            [
                mo.ui.plotly(_fig_dist, config={'displayModeBar': False}),
                mo.ui.plotly(_fig_time, config={'displayModeBar': False})
            ],
            widths="equal"
        )
    ])
    return (headline_distribution_summary,)


@app.cell(hide_code=True)
def _(address_list, int_optimism_user_profiles, mo, pyoso_db_conn, stringify):
    df_lifetime_metrics = mo.sql(
        f"""
        SELECT *
        FROM int_optimism_user_profiles
        WHERE user_address IN ({stringify(address_list)})
        ORDER BY total_gas_fees_on_op_mainnet DESC
        """,
        output=False,
        engine=pyoso_db_conn
    )
    return (df_lifetime_metrics,)


@app.cell(hide_code=True)
def _(
    address_list,
    int_optimism_dex_user_retention_monthly,
    mo,
    pyoso_db_conn,
    stringify,
):
    df_address_retention = mo.sql(
        f"""
        SELECT
          activity_month,
          retention_status,
          COUNT(DISTINCT user_address) AS users
        FROM int_optimism_dex_user_retention_monthly
        WHERE
          dex_project_name = 'rainbow'
          AND user_address IN ({stringify(address_list)})
        GROUP BY 1,2
        ORDER BY 1,2
        """,
        output=False,
        engine=pyoso_db_conn
    )
    return (df_address_retention,)


@app.cell(hide_code=True)
def _(df_lifetime_metrics, mo):
    _total_revenue = df_lifetime_metrics['total_gas_fees_on_op_mainnet'].sum()
    _dex_revenue = df_lifetime_metrics['total_gas_fees_on_dexs'].sum()
    _still_active = (df_lifetime_metrics['last_day_of_activity_on_op_mainnet'] >= '2025-08-01').mean() * 100

    _median_days_active = df_lifetime_metrics['total_days_active_on_op_mainnet'].median()
    _median_days_on_dexs = df_lifetime_metrics['total_days_active_on_dexs'].median()

    headline_user_ltv = f"These addresses have contributed a total of {_total_revenue:,.1f} ETH in revenue on OP Mainnet and {_dex_revenue:,.1f} ETH specifically on DEXs"

    _user_ltv_subtitle = f"""
    {_still_active:.0f}% of incentivized users were active on OP Mainnet in the last three months. The average user has spent a total of {_median_days_active} days on OP Mainnet and {_median_days_on_dexs} days specifically on DEXs.

    _The table below includes detailed lifetime metrics for each incentivized user on OP Mainnet and across OP's DEX ecosystem. This includes but is not limited to activity on Rainbow._
    """

    _df = df_lifetime_metrics.copy()
    _cols = [c.replace('_',' ').title() for c in _df.columns]
    _df.columns = _cols

    _pct_cols = ['Pct Gas Fees On Dexs', 'Pct Transactions On Dexs', 'Pct Days Active On Dexs']
    _df[_pct_cols] = _df[_pct_cols].apply(lambda x: x*100)

    mo.vstack([
        mo.md(f"## {headline_user_ltv}"),
        mo.md(_user_ltv_subtitle),
        mo.ui.table(
            _df.drop(columns=['Total Activity Ratio On Dexs']),
            show_column_summaries=False,
            show_data_types=False,
            format_mapping={c:'{:,.1f}%' for c in _pct_cols},
            freeze_columns_left=['User Address', 'Total Gas Fees On Op Mainnet', 'Pct Gas Fees On Dexs']
        )
    ])
    return (headline_user_ltv,)


@app.cell(hide_code=True)
def _(
    address_list,
    int_optimism_user_events_daily,
    mo,
    pd,
    pyoso_db_conn,
    stringify,
):
    df_incentived_user_activity = mo.sql(
        f"""
        SELECT
          DATE_TRUNC('MONTH', bucket_day) AS bucket_month,
          SUM(total_transactions) AS transactions,
          SUM(total_gas_fees) AS revenue,
          COUNT(DISTINCT user_address) AS active_users
        FROM int_optimism_user_events_daily
        WHERE user_address IN ({stringify(address_list)})
        GROUP BY 1
        ORDER BY 1
        """,
        output=False,
        engine=pyoso_db_conn
    )
    df_incentived_user_activity['bucket_month'] = pd.to_datetime(df_incentived_user_activity['bucket_month'])
    return (df_incentived_user_activity,)


@app.cell(hide_code=True)
def _(mo):
    metric_selector = mo.ui.dropdown(
        options={
            "Transactions": "transactions",
            "Revenue (gas fees)": "revenue",
            "Active users": "active_users",
        },
        value="Transactions",
        label="Select a metric:"
    )
    return (metric_selector,)


@app.cell(hide_code=True)
def _(
    df_funding_monthly,
    df_incentived_user_activity,
    go,
    metric_selector,
    mo,
    pd,
):
    _all_months = (
        pd.DataFrame({'bucket_month': 
            pd.date_range(
                start=df_incentived_user_activity['bucket_month'].min(),
                end=df_incentived_user_activity['bucket_month'].max(),
                freq='MS'
            )
        })
    )

    _df_funding = df_funding_monthly.copy()
    _df_funding = _all_months.merge(_df_funding, on='bucket_month', how='left')
    _df_funding['op_reward'] = _df_funding['op_reward'].fillna(0)
    _df_funding['rewards_distributed'] = _df_funding['op_reward'].cumsum()

    _df = (
        df_incentived_user_activity
        .merge(
            _df_funding[['bucket_month','rewards_distributed']],
            on='bucket_month',
            how='right'
        )
        .sort_values('bucket_month')
    )
    _df['transactions'] = _df['transactions'].fillna(0)

    def make_chart(metric):

        yvals = _df[metric]

        # Peak month and decline %
        peak_val = yvals.max()
        peak_idx = yvals.idxmax()
        peak_month = _df.loc[peak_idx, "bucket_month"].strftime("%b %Y")
        last_val = yvals.iloc[-1]

        if peak_val > 0:
            decline = max(0, 1 - (last_val / peak_val))
            decline_label = f"{decline*100:.0f}%"
        else:
            decline_label = "0%"

        if metric != 'revenue':
            metric_label = f'{peak_val:,.0f} {metric.replace('_',' ')}'
        else:
            metric_label = f'{peak_val:,.2f} ETH in revenue'
        headline = (
            f"Activity from the incentivized users on OP Mainnet "
            f"peaked at {metric_label} in {peak_month} "
            f"and has declined by {decline_label} since"
        )

        fig = go.Figure()
        fig.add_bar(
            x=_df['bucket_month'],
            y=yvals,
            name=f"{metric.replace('_',' ').title()} (incentivized users)",
            yaxis='y1',
            marker_color="#2C7FB8",
            hovertemplate='%{x|%b %Y}<br>%{y:,}<extra></extra>'
        )
        fig.add_trace(
            go.Scatter(
                x=_df['bucket_month'],
                y=_df['rewards_distributed'],
                mode='lines+markers',
                name='Cumulative OP distributed',
                yaxis='y2',
                line_shape='hvh',
                marker_color="#E34A33",
                hovertemplate='%{x|%b %Y}<br>Cumulative OP: %{y:,.0f}<extra></extra>'
            )
        )

        fig.update_layout(
            template='plotly_white',
            xaxis=dict(title='Month'),
            yaxis=dict(
                title=metric.replace('_',' ').title(),
                showgrid=False
            ),
            yaxis2=dict(
                title='Cumulative OP distributed',
                overlaying='y',
                side='right'
            ),
            legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='left', x=0),
            margin=dict(l=60, r=60, t=40, b=40)
        )

        return headline, fig


    headline_actity_vs_incentives, _fig = make_chart(metric_selector.value)

    mo.vstack([
        mo.md(f"## {headline_actity_vs_incentives}"),
        mo.hstack([
            mo.md("Late 2023 also coincides with the launch of Rainbow's points program."),
            metric_selector
        ]),
        mo.ui.plotly(_fig, config={'displayModeBar': False})
    ])
    return (headline_actity_vs_incentives,)


@app.cell(hide_code=True)
def _(df_address_retention, mo, pd, px):
    # Ensure activity_month is datetime
    df_address_retention['activity_month'] = pd.to_datetime(df_address_retention['activity_month'])

    # 1) Peak two months for "new" users
    new_by_month = (
        df_address_retention[df_address_retention['retention_status'] == 'new']
        .groupby('activity_month', as_index=False)['users']
        .sum()
    )

    peak_new = new_by_month.sort_values('users', ascending=False).head(2)
    peak_sum_new = peak_new['users'].sum()

    # nice month labels for the peak period
    _peak_month_labels = (
        peak_new.sort_values('activity_month')['activity_month']
        .dt.strftime('%b %Y')
        .tolist()
    )
    if len(_peak_month_labels) == 2:
        peak_month_label_str = f"{_peak_month_labels[0]} and {_peak_month_labels[1]}"
    else:
        peak_month_label_str = _peak_month_labels[0]

    # 2) Most recent three months – users who are NOT churned
    recent_months = (
        df_address_retention['activity_month']
        .sort_values()
        .unique()[-3:]
    )

    recent_non_churned = (
        df_address_retention[
            (df_address_retention['activity_month'].isin(recent_months)) &
            (df_address_retention['retention_status'] != 'churned')
        ]
        .groupby('activity_month')['users']
        .sum()
    )

    headline_rainbow_user_churn = (
        f"In its two peak months ({peak_month_label_str}), Rainbow onboarded a "
        f"total of {peak_sum_new:,.0f} new incentivized users"
    )

    _rainbow_user_churn_subtitle = (
        f"Over the most recent three months, only ~{recent_non_churned.sum()/3:,.0f} "
        f"users remain active (i.e., classified as retained, dormant, or resurrected) on Rainbow OP Mainnet."
    )

    _fig = px.bar(
        data_frame=df_address_retention,
        x='activity_month',
        y='users',
        color='retention_status',
        template="plotly_white"
    )

    mo.vstack([
        mo.md(f"## {headline_rainbow_user_churn}"),
        mo.md(_rainbow_user_churn_subtitle),
        mo.ui.plotly(_fig),
    ])
    return (headline_rainbow_user_churn,)


@app.cell(hide_code=True)
def _(int_optimism_dex_user_retention_monthly, mo, pyoso_db_conn):
    df_retention_by_cohort = mo.sql(
        f"""
        WITH cohort_stats AS (
          SELECT
            dex_project_name,
            cohort_month,
            cohort_age_months,
            COUNT(DISTINCT user_address) AS num_users,
            COUNT(DISTINCT CASE WHEN is_active = 1 THEN user_address END) AS num_retained_users
          FROM int_optimism_dex_user_retention_monthly
          WHERE dex_project_name NOT IN ('unknown', 'synthetix')
          GROUP BY 1,2,3
        )
        SELECT
          dex_project_name,
          cohort_month,
          cohort_age_months,
          num_users,
          num_retained_users,
          CAST(num_retained_users AS DOUBLE)/NULLIF(num_users,0) AS retention_rate
        FROM cohort_stats
        """,
        output=False,
        engine=pyoso_db_conn
    )
    return (df_retention_by_cohort,)


@app.cell(hide_code=True)
def _(df_retention_by_cohort, mo):
    _dex_list = sorted(df_retention_by_cohort['dex_project_name'].unique())
    _cohort_months = sorted(df_retention_by_cohort['cohort_month'].unique())
    dex1_select = mo.ui.dropdown(
        value='rainbow',
        options=_dex_list,
        label='Select a DEX',
        full_width=True
    )
    dex2_select = mo.ui.dropdown(
        value='metamask',
        options=_dex_list,
        label='Select a DEX to compare against',
        full_width=True
    )
    cohort_select = mo.ui.dropdown(
        options=_cohort_months,
        value='2023-02-01',
        label='Select a cohort month',
        full_width=True
    )
    show_retention = mo.ui.switch(
        value=True,
        label="Show percent retained",
    )
    return cohort_select, dex1_select, dex2_select, show_retention


@app.cell(hide_code=True)
def _(
    cohort_select,
    dex1_select,
    dex2_select,
    df_retention_by_cohort,
    mo,
    pd,
    px,
    show_retention,
):
    _df = df_retention_by_cohort[df_retention_by_cohort['cohort_month'] == cohort_select.value].copy()

    _projects = [dex1_select.value, dex2_select.value]
    _df = _df[_df['dex_project_name'].isin(_projects)]
    _df.sort_values(by=['cohort_age_months', 'dex_project_name'], inplace=True)

    _y = 'retention_rate' if show_retention.value else 'num_retained_users'
    _y_label = "Share of cohort retained" if show_retention.value else "Retained users"
    _cohort_label = pd.to_datetime(cohort_select.value).strftime('%b %Y')

    headline_retention_comparison = (
        f"How well do {dex1_select.value.title()} and {dex2_select.value.title()} retain their {_cohort_label} cohort of new users?"
    )
    subtitle = (
        "Each point shows how many users from that cohort are still active N months after their first trade."
        if not show_retention.value
        else "Each point shows the share of users from that cohort still active N months after their first trade."
    )

    _fig = px.line(
        data_frame=_df,
        x='cohort_age_months',
        y=_y,
        color='dex_project_name',
        color_discrete_map={dex1_select.value: '#e11d48', dex2_select.value: '#4b5563'},
        markers=True,
        template="plotly_white",
        labels={
            'cohort_age_months': 'Months since first trade',
            _y: _y_label,
            'dex_project_name': 'DEX'
        }
    )

    # cleaner styling
    _fig.update_traces(line=dict(width=2), marker=dict(size=6))
    if show_retention.value:
        _fig.update_yaxes(range=[0, 1], tickformat='.0%')
    else:
        _fig.update_yaxes(tickformat=',')

    _fig.update_layout(
        legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='left', x=0),
        margin=dict(l=60, r=20, t=20, b=40),
        xaxis=dict(showgrid=True, zeroline=False),
        yaxis=dict(showgrid=True, zeroline=False)
    )

    mo.vstack([
        mo.md(f"## {headline_retention_comparison}"),
        mo.md(subtitle),
        mo.hstack([dex1_select, dex2_select, cohort_select, show_retention], widths='equal', gap=2),
        mo.ui.plotly(_fig, config={'displayModeBar': False})
    ])
    return (headline_retention_comparison,)


@app.cell
def _(mo):
    mo.md(r"""
    ## Despite showing a higher ARPU, Rainbow also exhibits a higher churn rate than Metamask, netting out at very similar LTV levels
    """)
    return


@app.cell
def _(mo, pyoso_db_conn):
    ltv_df = mo.sql(
        f"""
        WITH
        cohort_users AS (
          SELECT
            r.user_address,
            r.dex_project_name,
            r.cohort_month
          FROM oso.int_optimism_dex_user_retention_monthly AS r
          WHERE
            r.cohort_month = DATE '2023-02-01'
            AND r.cohort_age_months = 0
        ),
        user_monthly_revenue AS (
          SELECT
            e.user_address,
            DATE_TRUNC('month', e.bucket_day) AS activity_month,
            SUM(e.total_gas_fees) AS monthly_gas_fees_all_activities
          FROM oso.int_optimism_user_events_daily AS e
          GROUP BY 1, 2
        ),
        cohort_user_months AS (
          SELECT
            r.dex_project_name,
            r.user_address,
            r.activity_month,
            r.cohort_month,
            r.cohort_age_months,
            r.is_active,
            r.retention_status
          FROM oso.int_optimism_dex_user_retention_monthly AS r
          JOIN cohort_users AS c
            ON r.user_address     = c.user_address
           AND r.dex_project_name = c.dex_project_name
           AND r.cohort_month     = c.cohort_month
          WHERE
            r.cohort_age_months BETWEEN 0 AND 11
        ),
        cohort_user_months_with_revenue AS (
          SELECT
            m.dex_project_name,
            m.cohort_month,
            m.activity_month,
            m.cohort_age_months,
            m.user_address,
            m.is_active,
            m.retention_status,
            COALESCE(ur.monthly_gas_fees_all_activities, 0) AS monthly_gas_fees_all_activities
          FROM cohort_user_months AS m
          LEFT JOIN user_monthly_revenue AS ur
            ON m.user_address   = ur.user_address
           AND m.activity_month = ur.activity_month
        ),
        per_user_first_churn AS (
          SELECT
            dex_project_name,
            cohort_month,
            user_address,
            MIN(
              CASE
                WHEN retention_status = 'churned' THEN cohort_age_months
                ELSE NULL
              END
            ) AS first_churn_age
          FROM cohort_user_months_with_revenue
          GROUP BY 1, 2, 3
        ),
        cohort_churn_stats AS (
          SELECT
            dex_project_name,
            cohort_month,
            COUNT(DISTINCT user_address) AS cohort_size,
            COUNT(DISTINCT CASE
              WHEN first_churn_age IS NOT NULL AND first_churn_age < 12 THEN user_address
            END) AS churned_within_horizon,
            SUM(
              CASE
                WHEN first_churn_age IS NULL OR first_churn_age >= 12 THEN 12
                ELSE first_churn_age
              END
            ) AS total_person_months_at_risk
          FROM per_user_first_churn
          GROUP BY 1, 2
        ),
        cohort_revenue_stats AS (
          SELECT
            dex_project_name,
            cohort_month,
            SUM(monthly_gas_fees_all_activities) AS total_revenue_all_activities
          FROM cohort_user_months_with_revenue
          WHERE
            cohort_age_months BETWEEN 0 AND 11
          GROUP BY 1, 2
        ),
        dex_level_ltv AS (
          SELECT
            c.dex_project_name,
            c.cohort_month,
            c.cohort_size,
            c.churned_within_horizon,
            c.total_person_months_at_risk,
            r.total_revenue_all_activities,
            CASE
              WHEN c.total_person_months_at_risk = 0 THEN NULL
              ELSE r.total_revenue_all_activities
                   / CAST(c.total_person_months_at_risk AS DOUBLE)
            END AS avg_monthly_revenue_per_address,
            CASE
              WHEN c.total_person_months_at_risk = 0 THEN NULL
              ELSE CAST(c.churned_within_horizon AS DOUBLE)
                   / CAST(c.total_person_months_at_risk AS DOUBLE)
            END AS avg_monthly_churn_rate
          FROM cohort_churn_stats AS c
          JOIN cohort_revenue_stats AS r
            ON c.dex_project_name = r.dex_project_name
           AND c.cohort_month     = r.cohort_month
        )

        SELECT
          dex_project_name,
          cohort_month,
          cohort_size,
          total_revenue_all_activities,
          avg_monthly_revenue_per_address,
          avg_monthly_churn_rate,
          CASE
            WHEN avg_monthly_churn_rate IS NULL OR avg_monthly_churn_rate = 0 THEN NULL
            ELSE 1 / avg_monthly_churn_rate
          END AS implied_avg_lifetime_months,
          CASE
            WHEN avg_monthly_churn_rate IS NULL OR avg_monthly_churn_rate = 0 THEN NULL
            ELSE avg_monthly_revenue_per_address * (1 / avg_monthly_churn_rate)
          END AS ltv_gas_fees_per_address
        FROM dex_level_ltv
        WHERE dex_project_name NOT IN ('unknown', 'synthetix')
        ORDER BY dex_project_name, cohort_month
        """,
        engine=pyoso_db_conn
    )
    return (ltv_df,)


@app.cell
def _(ltv_df, mo, px):
    ltv_avg_df = (
        ltv_df
        .groupby("dex_project_name", as_index=False)["ltv_gas_fees_per_address"]
        .mean()
        .rename(columns={"ltv_gas_fees_per_address": "avg_ltv_gas_fees_per_address"})
    )

    # Sort by size (avg LTV) descending
    ltv_avg_df = ltv_avg_df.sort_values(
        by="avg_ltv_gas_fees_per_address",
        ascending=False
    )

    ltv_fig = px.bar(
        data_frame=ltv_avg_df,
        x="dex_project_name",
        y="avg_ltv_gas_fees_per_address",
        template="plotly_white",
    )

    ltv_fig.update_layout(
        xaxis_title="DEX",
        yaxis_title="Average LTV (gas fees per address)",
        bargap=0.2,
    )

    mo.vstack([
        mo.md("## Average LTV by DEX"),
        mo.ui.plotly(ltv_fig),
    ])
    return (ltv_avg_df,)


@app.cell
def _(dex1_select, dex2_select, ltv_avg_df, mo, px):
    _projects = [dex1_select.value, dex2_select.value]

    ltv_avg_df_comp = ltv_avg_df[
        ltv_avg_df["dex_project_name"].isin([p for p in _projects if p is not None])
    ].copy()

    ltv_comp_fig = px.bar(
        data_frame=ltv_avg_df_comp,
        x="dex_project_name",
        y="avg_ltv_gas_fees_per_address",
        color="dex_project_name",
        color_discrete_map={
            dex1_select.value: "red",
            dex2_select.value: "grey",
        },
        template="plotly_white",
    )

    ltv_comp_fig.update_layout(
        xaxis_title="DEX",
        yaxis_title="Average LTV (gas fees per address)",
        bargap=0.4,
        legend=dict(
            title="Project",
            orientation="v",
            y=0.5,
            yanchor="middle",
            x=1.02,
            xanchor="left",
        ),
        showlegend=True,
    )

    mo.vstack([
        mo.md("## Compare Average LTV by DEX"),
        mo.hstack([dex1_select, dex2_select], widths="equal", gap=2),
        mo.ui.plotly(ltv_comp_fig),
    ])
    return


@app.cell
def _(mo):
    mo.md(r"""
    # Appendix
    """)
    return


@app.cell
def _():
    # df_ltv = mo.sql(
    #     f"""
    #     SELECT
    #         user_address,
    #         SUM(CASE WHEN project_name = 'rainbow' THEN total_gas_fees ELSE 0 END) AS rainbow_gas_fees,
    #         SUM(total_gas_fees) AS total_dex_gas_fees,
    #         MAX(total_gas_fees_on_op_mainnet) AS total_gas_fees_on_op_mainnet,
    #         MIN(date_first_transaction) AS date_first_dex_transaction,
    #         MIN(first_month_of_activity_on_op_mainnet) AS first_month_of_activity_on_op_mainnet
    #     FROM int_optimism_dex_user_ltv
    #     WHERE user_address IN ({stringify(df_cac['address'])})
    #     GROUP BY 1
    #     """,
    #     engine=pyoso_db_conn
    # )
    return


@app.cell
def _():
    # df_cac_ltv = df_cac.merge(df_ltv, left_on='address', right_on='user_address', how='left')
    # df_cac_ltv = df_cac_ltv[['address', 'op_reward', 'rainbow_gas_fees', 'total_dex_gas_fees', 'total_gas_fees_on_op_mainnet', 'date_first_dex_transaction', 'first_month_of_activity_on_op_mainnet']]

    # print(df_cac_ltv['op_reward'].sum() * 0.75)
    # print(df_cac_ltv['total_gas_fees_on_op_mainnet'].sum() * 3500)

    # df_cac_ltv
    return


@app.cell
def _():
    #df_rainbow.groupby('Cohort')[['Users', 'Fees (ETH)', 'Transactions']].sum()
    return


@app.cell
def _():
    # df_fee_share = mo.sql("""
    # SELECT
    #   bucket_day AS "Date",
    #   project_name AS "DEX",
    #   SUM(tx_fees_eth) AS "Fees (ETH)",
    #   SUM(tx_count) AS "Transactions"
    # FROM int_optimism_dex_user_cohorts
    # GROUP BY 1,2
    # ORDER BY 1,2
    # """, engine=pyoso_db_conn)

    # px.area(
    #     data_frame=df_fee_share,
    #     x='Date',
    #     y='Transactions',
    #     color='DEX'
    # )
    return


@app.cell
def _():
    stringify = lambda arr: "'" + "','".join(arr) + "'"
    return (stringify,)


@app.cell
def _():
    import numpy as np
    import pandas as pd
    import plotly.express as px
    import plotly.graph_objects as go
    return go, pd, px


@app.cell
def setup_pyoso():
    # This code sets up pyoso to be used as a database provider for this notebook
    # This code is autogenerated. Modification could lead to unexpected results :)
    import pyoso
    import marimo as mo
    pyoso_db_conn = pyoso.Client().dbapi_connection()
    return mo, pyoso_db_conn


@app.cell
def _(mo):
    mo.md(r"""
    ### Incentives per User Address

    The following is a recreation of: https://dune.com/queries/2175264/3562693 for BigQuery that also traces the transfers from the recipient multisig address.

    ```sql

    CREATE TEMP FUNCTION hex_to_decimal_string(h STRING)
    RETURNS STRING
    LANGUAGE js AS "\"\"
      if (h === null) return null;
      h = h.toLowerCase();
      if (h.startsWith('0x')) h = h.slice(2);
      return BigInt('0x' + h).toString(10);
    "\"\";

    WITH base_logs AS (
      SELECT
        transaction_hash,
        dt,
        LOWER(address) AS token,
        SPLIT(topics, ',') AS topics_arr,
        data
      FROM `optimism_superchain_raw_onchain_data.logs`
      WHERE
        chain='op'
        AND LOWER(address)='0x4200000000000000000000000000000000000042'  -- OP token
        AND dt BETWEEN DATE '2023-02-20' AND DATE '2024-01-02'
    ),

    op_transfer_logs AS (
      SELECT
        transaction_hash,
        dt,
        topics_arr,
        data
      FROM base_logs
      WHERE topics_arr[OFFSET(0)]
            = '0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef'
    ),

    decoded AS (
      SELECT
        transaction_hash,
        dt,
        LOWER(CONCAT('0x',SUBSTR(topics_arr[OFFSET(1)],27))) AS from_addr,
        LOWER(CONCAT('0x',SUBSTR(topics_arr[OFFSET(2)],27))) AS to_addr,
        CAST(hex_to_decimal_string(SUBSTR(data,3)) AS NUMERIC) AS amount_wei
      FROM op_transfer_logs
    ),

    filtered AS (
      SELECT *
      FROM decoded
      WHERE
        -- first_week_tx
        (
          from_addr='0x6e9fcf73b75aad9f52aeb7d46c3ab0b7c7d39c5f'
          AND dt >= '2023-02-20'
          AND dt < '2023-02-22'
        )
        OR
        -- second_week_tx
        (
          from_addr='0x4dd833a3f11217b5f298a3c3172c9659cf366ab9'
          AND dt >= '2023-02-27'
          AND dt < '2023-03-01'
        )
        OR
        -- third_week_tx
        (
          from_addr='0xc23caa89276b45de87bdaf3b3a54a393a4534eae'
          AND dt >= '2023-03-06'
          AND dt < '2023-03-07'
        )
        OR
        -- direct transfers
        (
          from_addr='0x9d62e3f4f5a2ef4f446da692b07860f3c78ceaa4'
          AND dt >= '2023-10-31'
          AND dt < '2024-01-02'
        )
    )

    SELECT
      dt,
      to_addr AS address,
      SUM(amount_wei)/1e18 AS op_reward
    FROM filtered
    GROUP BY 1,2


    ```
    """)
    return


@app.cell
def _():
    return


if __name__ == "__main__":
    app.run()
