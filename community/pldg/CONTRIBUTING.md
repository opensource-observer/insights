# Contributing Your Proof-of-Work Notebook

Thank you for your interest in contributing to OSO through the PLDG program!

## About the Proof-of-Work

PLDG contributors complete a **proof-of-work assignment** before being assigned new issues. This ensures contributors have the skills needed to work on OSO data quality and analysis.

**Your task:** Create a marimo notebook that audits an OSO data pipeline from staging sources through to mart-level metrics.

**Goal:** Pass the proof-of-work → get access to new issues.

This guide walks you through creating and submitting your proof-of-work notebook.

---

## Table of Contents

- [Notebook Setup](#notebook-setup)
- [What Makes a Good Notebook](#what-makes-a-good-notebook)
- [Success Criteria](#success-criteria)
- [Testing Your Notebook](#testing-your-notebook)
- [Submission Workflow](#submission-workflow)
- [Code Style Guidelines](#code-style-guidelines)
- [Common Marimo Errors](#common-marimo-errors)

---

## Notebook Setup

### Using pyoso to Query OSO Data

All notebooks use `pyoso` to query the OSO data warehouse. No local database needed!

**Required setup cell** - Every notebook MUST include this:

```python
@app.cell
def setup_pyoso():
    # This code sets up pyoso to be used as a database provider for this notebook
    # This code is autogenerated. Modification could lead to unexpected results :)
    import marimo as mo
    from pyoso import Client
    client = Client()
    pyoso_db_conn = client.dbapi_connection()
    return mo, pyoso_db_conn
```

**Querying data** - Use `mo.sql()` in your cells:

```python
@app.cell
def _(mo, pyoso_db_conn):
    df = mo.sql(
        f"""
        SELECT * FROM oso.projects_v1 LIMIT 10
        """,
        engine=pyoso_db_conn
    )
    return (df,)
```

**Running out of credits?** Request access to the "pldg" organization in Discord.

### Marimo Commands

**Development mode** - Edit and test your notebook:
```bash
uv run marimo edit your_notebook.py
```

**Preview mode** - See how reviewers will see it (code hidden):
```bash
uv run marimo run your_notebook.py
```

**Structure check** - Validate without executing (run this first!):
```bash
uv run marimo check your_notebook.py
```

---

## What Makes a Good Notebook?

A quality proof-of-work submission demonstrates both technical competence and domain understanding.

### 1. Data Lineage Documentation

**Document the data flow:**
- Which staging tables feed into the mart model?
- What intermediate models exist in the pipeline?
- Show the full lineage with SQL queries

**Example:**
```sql
-- Staging: oso.stg_github__events
-- Intermediate: oso.int_events_daily__github
-- Mart: oso.timeseries_metrics_by_project_v0
```

### 2. Quality Checks (3 required)

The template includes 3 essential data quality checks that every submission must perform:

**Required checks:**
1. **Presence** - Verify row counts at each pipeline stage (staging → intermediate → mart)
   - Shows data flow through the pipeline
   - Identifies data loss or unexpected growth between stages

2. **Date Coverage** - Validate time-series data ranges and gaps
   - Ensures data freshness and completeness
   - Detects pipeline failures or missing data periods

3. **Duplicates** - Detect duplicate records on key fields
   - Identifies data quality issues from joins or ingestion
   - Validates primary key uniqueness

**Going beyond (optional but encouraged):**
- Null analysis for critical fields
- Distribution analysis (outliers, unexpected values)
- Business logic validation (calculated fields match expectations)
- Sample validation with well-known projects

### 3. Business Logic Validation

Go beyond generic checks:
- Does the data match expected patterns for this domain?
- Are metrics calculating correctly?
- Spot-check 3-5 well-known projects (Uniswap, Optimism, etc.)
- Test edge cases and boundary conditions

### 4. Visualizations

**Include charts showing:**
- Distribution charts (histograms, box plots)
- Time-series plots (data coverage over time)
- Comparison charts (expected vs actual counts)
- Heatmaps (missing data patterns)

**Use plotly for interactivity:**
```python
import plotly.express as px

fig = px.line(df, x='date', y='count', title='Daily Record Counts')
mo.ui.plotly(fig)
```

### 5. Cell Organization

Marimo notebooks work best when concerns are separated cleanly:

**Pattern to follow:**
- **Markdown cells**: Pure documentation using `mo.md(r"""...""")`
- **SQL cells**: Pure queries using `mo.sql()` with `engine=pyoso_db_conn`
- **Python cells**: Pure logic/visualization (last expression is auto-displayed)

**Example:**
```python
# Markdown cell - section header
@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    ## Check 1: Row Counts
    Verify data exists at each stage...
    """)
    return

# SQL cell - query data
@app.cell
def _(mo, pyoso_db_conn):
    staging_count = mo.sql(
        f"""
        SELECT COUNT(*) as count FROM oso.stg_github__events
        """,
        engine=pyoso_db_conn
    )
    return (staging_count,)

# Python cell - create visualization
@app.cell
def _(staging_count, px):
    px.bar(staging_count, x='stage', y='count')
    return

# Markdown cell - explain results
@app.cell(hide_code=True)
def _(mo, staging_count):
    mo.md(f"""
    **Results:** {staging_count['count'].iloc[0]:,.0f} rows
    """)
    return
```

### Bonus Points

- **Real issues discovered** - Finding actual data quality problems is valuable
- **Clear analysis** - Add markdown cells explaining what each check reveals
- **Pipeline documentation** - Complete the pipeline documentation section

---

## Success Criteria

Your notebook must meet ALL of these requirements:

- ✅ **Runs successfully** - Uses pyoso, executes without errors
- ✅ **Structure valid** - Passes `uv run marimo check your_notebook.py`
- ✅ **Pipeline coverage** - Audits all 3 stages (`oso.stg_*` → `oso.int_*` → `oso.*_v0`)
- ✅ **Quality checks** - Includes all 3 required checks (presence, dates, duplicates)
- ✅ **Well documented** - Clear markdown cells explaining analysis
- ✅ **Separated concerns** - Markdown, SQL, and Python in separate cells
- ✅ **Visualizations** - Uses plotly charts to display data health
- ✅ **OSO naming** - Demonstrates understanding of `stg_`, `int_`, and `_v0` / `_v1` conventions
- ✅ **Pipeline documented** - Completes the pipeline documentation section
- ✅ **Proper naming** - Follows `{data_source}_{username}.py` convention

---

## Testing Your Notebook

Test thoroughly before submitting. Follow this workflow:

### 1. Quick Structure Check (ALWAYS RUN FIRST)

```bash
uv run marimo check your_notebook.py
```

**This catches:**
- Multiple definition errors (same variable in multiple cells)
- Cycle errors (circular dependencies)
- Import star errors (`from module import *` not allowed)
- Syntax errors

**Fix all errors before proceeding.** This is the fastest way to validate your notebook.

### 2. Development Mode

```bash
uv run marimo edit your_notebook.py
```

**Verify:**
- All cells execute without errors (no red indicators)
- SQL queries return results successfully
- Visualizations render correctly
- Interactive elements work (if applicable)
- Documentation is clear and complete

### 3. Preview Mode

```bash
uv run marimo run your_notebook.py
```

**Check:**
- Read-only view looks professional
- Code is hidden by default (as reviewers will see it)
- All outputs display correctly
- Navigation works smoothly

### 4. Script Execution (Optional)

```bash
uv run your_notebook.py
```

Validates that all cells execute sequentially. May fail on database connections without environment variables set.

### Pre-Submission Checklist

Before creating your gist, verify:

- [ ] `uv run marimo check` passes with no errors
- [ ] Opens successfully in edit mode
- [ ] All SQL queries execute without errors
- [ ] All visualizations render correctly
- [ ] Markdown cells are filled in with analysis
- [ ] Pipeline documentation section is complete
- [ ] Markdown, SQL, and Python are in separate cells
- [ ] No red error indicators in marimo editor
- [ ] Runs successfully in app mode (`marimo run`)
- [ ] Notebook follows naming convention
- [ ] You've tested with your OSO_API_KEY

---

## Submission Workflow

### Step 1: Create Your Notebook

**Do NOT submit a PR yet!** Start with a gist for easier iteration.

1. **Start with the template:**
   ```bash
   cp health_check_template.py my_notebook.py
   ```

2. **Choose ONE data source** to audit (see README for options)

3. **Develop and test** using the testing workflow above

4. **Document thoroughly** - Explain your analysis, not just what the code does

5. **Run the pre-submission checklist** - Fix all issues

### Step 2: Submit for Review (GitHub Gist)

1. **Create a public GitHub gist** with your notebook file

2. **[Create a new submission issue](https://github.com/opensource-observer/insights/issues/new?template=pldg-data-submission.md)** with:
   - Link to your gist
   - Data source audited
   - 2-3 sentence summary of key findings

**Example submission comment:**
```markdown
**Gist:** https://gist.github.com/alice/abc123def456
**Data source:** staging.github → oso.timeseries_metrics_by_project_v0
**Findings:** Identified 15% null values in stargazers_count field from 2019-2020,
suggesting incomplete GitHub API backfill. Date coverage spans 2015-2025 with notable
gap in Q2 2020. All tested projects (Uniswap, Optimism, Compound, Aave, MakerDAO)
validated successfully with expected metric values.
```

3. **Wait for review** - OSO maintainers will review within **5 business days**

4. **Iterate if needed:**
   - Reviewers may request changes
   - Update your gist based on feedback
   - Comment again when ready for re-review
   - **Do not submit a PR until explicitly approved**

### Step 3: Submit PR (After Approval Only)

Once a maintainer approves your gist:

1. **Fork the repository:**
   ```bash
   gh repo fork opensource-observer/insights
   ```

2. **Create a branch:**
   ```bash
   git checkout -b pldg/your-name-data-source
   # Example: git checkout -b pldg/alice-github-metrics
   ```

3. **Add your notebook with proper naming:**

   **Naming convention:** `{data_source}_{your_github_username}.py`

   **Examples:**
   - `github_metrics_alice.py`
   - `gitcoin_grants_bob.py`
   - `defillama_tvl_charlie.py`
   - `oss_directory_projects_dana.py`

   ```bash
   cp your_notebook.py insights/community/pldg/{data_source}_{username}.py
   ```

4. **Commit and push:**
   ```bash
   git add community/pldg/{data_source}_{username}.py
   git commit -m "Add PLDG health-check: {data_source} by @{username}"
   git push origin pldg/your-name-data-source
   ```

5. **Create PR:**
   - Use GitHub UI or `gh pr create`
   - Reference your submission issue in the description
   - Link to your approved gist
   - Wait for final review and merge

### Step 4: Get Onboarded (After PR Merge)

Once your PR is merged, you'll receive:

1. **Discord/Gather invite** - Join the OSO community
2. **Mentor assignment** - Paired with an OSO maintainer
3. **Issue access** - Assigned your first "good first issue" (paid work)
4. **Regular check-ins** - Weekly or bi-weekly syncs with your mentor

**Congratulations!** You're now an approved PLDG contributor.

---

## Code Style Guidelines

Follow these conventions for consistency across submissions.

### Python

- **Follow PEP 8** - Standard Python style guide
- **Descriptive variable names** - `df_projects` not `df1`
- **Prefix temporaries with `_`** - Avoids marimo multiple definition errors
- **Type hints optional** - But appreciated for complex functions

**Example:**
```python
# Good
@app.cell
def _(mo, pyoso_db_conn):
    df_staging_repos = mo.sql(
        """SELECT * FROM oso.stg_github__repos""",
        engine=pyoso_db_conn
    )
    return (df_staging_repos,)

# Bad - generic name, reused across cells
@app.cell
def _(mo, pyoso_db_conn):
    df = mo.sql("""SELECT * FROM oso.projects_v1""", engine=pyoso_db_conn)  # 'df' defined in multiple cells!
    return (df,)
```

### SQL

- **Clear, readable formatting** - Proper indentation
- **One column per line** in SELECT (when practical)
- **Explicit JOINs** - Always specify join conditions
- **Comments for complex logic** - Explain non-obvious WHERE clauses

**Example:**
```sql
SELECT
    p.project_id,
    p.project_name,
    p.project_source,
    COUNT(a.artifact_id) as artifact_count
FROM oso.projects_v1 p
LEFT JOIN oso.artifacts_by_project_v1 a
    ON p.project_id = a.project_id
WHERE p.project_source = 'OSS_DIRECTORY'
GROUP BY p.project_id, p.project_name, p.project_source
ORDER BY artifact_count DESC
```

### Markdown

- **Use headers for structure** - H2 for major sections, H3 for subsections
- **Explain analysis** - Why these checks matter, what patterns mean
- **Context over code** - Don't just describe what the code does
- **Bullet points for lists** - Easier to scan than paragraphs

**Example:**
```markdown
## Check 3: Duplicate Detection

This check identifies duplicate records in the mart model based on the primary key.
Duplicates can indicate issues with the join logic or data ingestion processes.

**Why this matters:** Duplicate records can inflate metrics and cause incorrect
aggregations in downstream analyses.
```

### Comments

- **Explain WHY, not WHAT** - Code should be self-explanatory
- **Document assumptions** - Note any limitations or edge cases
- **Highlight known issues** - Be transparent about incomplete checks

**Example:**
```python
# Check for nulls in critical fields
# Note: project_name can legitimately be null for some sources (e.g., blockchain addresses)
# but should always be present for OSS_DIRECTORY projects
```

---

## Common Marimo Errors

Marimo enforces constraints for reproducibility. Understanding these errors helps you write correct notebooks.

### Multiple Definitions Error

**Problem:** A variable is defined in more than one cell.

**Common causes:**
- Reusing generic names like `df`, `fig`, `result`
- Loop variables (e.g., `row`, `i`) in multiple cells
- Temporary variables not prefixed with `_`

**Solution:** Use unique, descriptive names OR prefix temporaries with `_`

```python
# ❌ Bad - 'df' defined in multiple cells
@app.cell
def _(mo, pyoso_db_conn):
    df = mo.sql("SELECT * FROM oso.projects_v1", engine=pyoso_db_conn)
    return (df,)

@app.cell
def _(mo, pyoso_db_conn):
    df = mo.sql("SELECT * FROM oso.timeseries_metrics_by_project_v0", engine=pyoso_db_conn)  # Error!
    return (df,)

# ✅ Good - unique names
@app.cell
def _(mo, pyoso_db_conn):
    df_projects = mo.sql("SELECT * FROM oso.projects_v1", engine=pyoso_db_conn)
    return (df_projects,)

@app.cell
def _(mo, pyoso_db_conn):
    df_metrics = mo.sql("SELECT * FROM oso.timeseries_metrics_by_project_v0", engine=pyoso_db_conn)
    return (df_metrics,)
```

### Loop Variables

**Problem:** Loop variables create definitions. Multiple loops with same variable names conflict.

```python
# ❌ Bad - 'row' defined in both loops
@app.cell
def _(df_projects):
    for _, row in df_projects.iterrows():
        project = row['name']  # Error! 'project' also defined below
    return

@app.cell
def _(df_metrics):
    for _, row in df_metrics.iterrows():  # Error! 'row' already defined
        project = row['project']  # Error! 'project' already defined
    return

# ✅ Good - prefix ALL loop variables with _
@app.cell
def _(df_projects):
    for _, _row in df_projects.iterrows():
        _project = _row['name']
        _value = _row['amount']
    return

@app.cell
def _(df_metrics):
    for _, _row in df_metrics.iterrows():
        _project = _row['project']
        _value = _row['amount']
    return
```

### Cycles Error

**Problem:** Two or more cells have circular dependencies.

**Example:**
- Cell A defines `x` and reads `y`
- Cell B defines `y` and reads `x`

**Solution:** Restructure to break the cycle - compute in one cell or use intermediate variables.

```python
# ❌ Bad - cycle between cells
@app.cell
def _(y):
    x = y + 1
    return (x,)

@app.cell
def _(x):
    y = x + 1  # Error! Cycle: x depends on y, y depends on x
    return (y,)

# ✅ Good - compute together
@app.cell
def _():
    base = 10
    x = base + 1
    y = x + 1
    return x, y
```

### Import Star Error

**Problem:** `from module import *` is not allowed.

```python
# ❌ Bad
from pandas import *

# ✅ Good
import pandas as pd
from plotly.express import line, bar
```

### More Resources

See the [marimo error documentation](https://docs.marimo.io/guides/understanding_errors/) for detailed explanations and solutions.

---

## Questions?

- **Discord**: Ask in #pldg-onboarding
- **GitHub**: Create a [submission issue](https://github.com/opensource-observer/insights/issues/new?template=pldg-data-submission.md)
- **Marimo Docs**: https://docs.marimo.io
- **OSO Docs**: https://docs.oso.xyz

---

**Thank you for contributing to OSO!** Your data quality work helps improve the platform for everyone.
