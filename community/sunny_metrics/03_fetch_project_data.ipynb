{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0683d20",
   "metadata": {},
   "source": [
    "# 03 Fetch onchain data about projects\n",
    "\n",
    "Grabs lots of data from differnet sources. Requires credentials and several GB storage. Not for the faint of heart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "def9dccc-48cc-412f-9d19-baaa588d9f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from google.cloud import bigquery\n",
    "from dune_client.types import QueryParameter\n",
    "from dune_client.client import DuneClient\n",
    "from dune_client.query import QueryBase\n",
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a80a1b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "PROJECT = 'opensource-observer'\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"../../oso_gcp_credentials.json\"\n",
    "client = bigquery.Client()\n",
    "\n",
    "DUNE_API_KEY = os.getenv('DUNE_API_KEY')\n",
    "dune = DuneClient(DUNE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdc49a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "REFRESH_DUNE = False\n",
    "REFRESH_OSO = False\n",
    "REFRESH_FARCASTER = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45d7a3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVENT_TABLES = {}\n",
    "EVENT_COLS = ['uuid', 'chain', 'address', 'contract_type', 'user_address',\n",
    "              'date', 'count_transactions', 'data_source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cd32909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contract_type       chain     \n",
       "dapp_contract       Base          85\n",
       "                    Optimism      39\n",
       "                    Zora          10\n",
       "                    Mode           8\n",
       "factory_contract    Base          16\n",
       "                    Optimism       5\n",
       "                    Mode           1\n",
       "invalid_contract    Base           3\n",
       "                    Optimism       1\n",
       "pending_cyber       Cyber          2\n",
       "pending_kroma       Kroma          5\n",
       "pending_lisk        Lisk           2\n",
       "pending_mint        Mint          11\n",
       "pending_orderly     Orderly        2\n",
       "pending_polynomial  Polynomial     2\n",
       "pending_redstone    Redstone       1\n",
       "pending_swanchain   SwanChain      5\n",
       "token_contract      Optimism      81\n",
       "                    Base          46\n",
       "trace_contract      Base          78\n",
       "                    Optimism      34\n",
       "                    Mode           3\n",
       "                    Zora           1\n",
       "unknown             Base          29\n",
       "                    Optimism      28\n",
       "                    Mode           2\n",
       "                    Zora           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_PROJECTS = pd.read_csv('data/apps/project_apps_labeled.csv', index_col=0)\n",
    "DF_PROJECTS.groupby('contract_type')['chain'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "645cfabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify_addresses(list_of_types, filter_col='contract_type', context='oso'):\n",
    "    filtered_projects = DF_PROJECTS[DF_PROJECTS[filter_col].isin(list_of_types)]\n",
    "    address_list = list(filtered_projects['address'].unique())\n",
    "    if context == 'dune':\n",
    "        address_list_str = ',\\n\\t\\t'.join(address_list)\n",
    "    elif context == 'oso':\n",
    "        address_list_str = \"'\" + \"','\".join(address_list) + \"'\" \n",
    "    return address_list_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dc256b",
   "metadata": {},
   "source": [
    "## Part 1. Dune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b9ed7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dune_events(dune_dataframe, data_source_name):\n",
    "\n",
    "    def parse_string(row):\n",
    "        matches = re.findall(r'\\[(\\d{4}-\\d{2}-\\d{2}) (\\d+\\.?\\d*)\\]', row)\n",
    "        return [(date, float(value)) for date, value in matches]\n",
    "\n",
    "    dune_dataframe_copy = dune_dataframe.copy()\n",
    "    dune_dataframe_copy['transactions'] = dune_dataframe_copy['transaction_details'].apply(parse_string)\n",
    "\n",
    "    projects_copy = DF_PROJECTS.reset_index().copy()\n",
    "    projects_copy['lbl'] = projects_copy['chain'].str.lower() + ' ' + projects_copy['address']\n",
    "\n",
    "    merge_settings = dict(left_on='lbl', right_on='contract_address', how='inner')\n",
    "    merged_df = pd.merge(projects_copy, dune_dataframe_copy, **merge_settings)\n",
    "    merged_df['transactions'] = merged_df['transactions'].apply(lambda x: [tuple(t) for t in x])\n",
    "    exploded_df = merged_df.explode('transactions')\n",
    "    exploded_df[['date', 'count_transactions']] = pd.DataFrame(\n",
    "        exploded_df['transactions'].tolist(), index=exploded_df.index\n",
    "    )\n",
    "    exploded_df['data_source'] = data_source_name\n",
    "    \n",
    "    final_df = exploded_df[EVENT_COLS]\n",
    "    print(f\"Processed {len(final_df)} Dune transactions.\")\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29fdf864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows imported: 488177\n",
      "Processed 1266967 Dune transactions.\n"
     ]
    }
   ],
   "source": [
    "address_list_str = stringify_addresses(['trace_contract', 'factory_contract'], context='dune')\n",
    "\n",
    "query_sql = f\"\"\"\n",
    "    with pre_agg_events as (\n",
    "        select\n",
    "            to_char(evt_block_time, 'yyyy-mm-dd') as block_date,\n",
    "            concat(blockchain, ' ', cast(\"from\" as varchar)) as contract_address,\n",
    "            \"to\" as user_address,\n",
    "            count(distinct evt_tx_hash) as count_transactions\n",
    "        from evms.erc20_transfers\n",
    "        where\n",
    "            blockchain in ('base', 'optimism', 'zora')\n",
    "            and evt_block_time between date('2024-02-01') and date('2024-09-01')\n",
    "            and \"from\" in (\n",
    "                    {address_list_str}\n",
    "              )\n",
    "        group by 1,2,3\n",
    "    )\n",
    "    select\n",
    "      contract_address,\n",
    "      user_address,\n",
    "      array_agg(\n",
    "        (block_date, count_transactions)\n",
    "        order by\n",
    "          block_date\n",
    "      ) as transaction_details\n",
    "    from\n",
    "      pre_agg_events\n",
    "    group by\n",
    "      contract_address,\n",
    "      user_address\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "source_name = 'erc20_transfers'\n",
    "if REFRESH_DUNE:\n",
    "    query_id = dune.create_query(name=source_name, query_sql=query_sql, is_private=False)\n",
    "    query = QueryBase(name=source_name, query_id=query_id.base.query_id)\n",
    "    erc20_df = dune.run_query_dataframe(query)\n",
    "    erc20_df.to_parquet(f'data/raw_metric_data/dune_raw_{source_name}.parquet')\n",
    "else:\n",
    "    erc20_df = pd.read_parquet(f'data/raw_metric_data/dune_raw_{source_name}.parquet')\n",
    "\n",
    "print(\"Rows imported:\", len(erc20_df))\n",
    "\n",
    "EVENT_TABLES.update({\n",
    "    source_name: process_dune_events(erc20_df, source_name)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23efa34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows imported: 1004720\n",
      "Processed 3215195 Dune transactions.\n"
     ]
    }
   ],
   "source": [
    "address_list_str = stringify_addresses(['token_contract'], context='dune')\n",
    "\n",
    "query_sql = f\"\"\"\n",
    "    with\n",
    "      transfers as (\n",
    "        select\n",
    "          concat(blockchain, ' ', cast(contract_address as varchar)) as contract_address,\n",
    "          to_char(block_date, 'yyyy-mm-dd') as block_date,\n",
    "          tx_from,\n",
    "          tx_to\n",
    "        from\n",
    "          tokens.transfers as transfers\n",
    "        where\n",
    "          contract_address in (\n",
    "                {address_list_str}\n",
    "          )\n",
    "          and blockchain in ('base', 'optimism', 'zora')\n",
    "          and block_date between date('2024-02-01') and date('2024-09-01')\n",
    "      ),\n",
    "      union_events as (\n",
    "        select\n",
    "          contract_address,\n",
    "          block_date,\n",
    "          tx_from as user_address,\n",
    "          0.5 as amount\n",
    "        from\n",
    "          transfers\n",
    "        union all\n",
    "        select\n",
    "          contract_address,\n",
    "          block_date,\n",
    "          tx_to as user_address,\n",
    "          0.5 as amount\n",
    "        from\n",
    "          transfers\n",
    "      ),\n",
    "      pre_agg_events as (\n",
    "        select\n",
    "          contract_address,\n",
    "          block_date,\n",
    "          user_address,\n",
    "          sum(amount) as count_transactions\n",
    "        from\n",
    "          union_events\n",
    "        group by\n",
    "          contract_address,\n",
    "          block_date,\n",
    "          user_address\n",
    "      )\n",
    "    select\n",
    "      contract_address,\n",
    "      user_address,\n",
    "      array_agg(\n",
    "        (block_date, count_transactions)\n",
    "        order by\n",
    "          block_date\n",
    "      ) as transaction_details\n",
    "    from\n",
    "      pre_agg_events\n",
    "    group by\n",
    "      contract_address,\n",
    "      user_address\n",
    "\"\"\"\n",
    "\n",
    "source_name = 'token_transfers'\n",
    "if REFRESH_DUNE:\n",
    "    query_id = dune.create_query(name=source_name, query_sql=query_sql, is_private=False)\n",
    "    query = QueryBase(name=source_name, query_id=query_id.base.query_id)\n",
    "    tokens_df = dune.run_query_dataframe(query)\n",
    "    tokens_df.to_parquet(f'data/raw_metric_data/dune_raw_{source_name}.parquet')\n",
    "else:\n",
    "    tokens_df = pd.read_parquet(f'data/raw_metric_data/dune_raw_{source_name}.parquet')\n",
    "\n",
    "print(\"Rows imported:\", len(tokens_df))\n",
    "\n",
    "EVENT_TABLES.update({\n",
    "    source_name: process_dune_events(tokens_df, source_name)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d750d536",
   "metadata": {},
   "source": [
    "## Part 2. Get OSO dapp transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b91d3282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_oso_events(oso_dataframe, data_source_name):\n",
    "\n",
    "    projects_copy = DF_PROJECTS.reset_index().copy()\n",
    "\n",
    "    merged_df = pd.merge(\n",
    "        projects_copy,\n",
    "        oso_dataframe,\n",
    "        left_on=['address', 'chain'],\n",
    "        right_on=['contract_address', 'chain'],\n",
    "        how='inner'\n",
    "    )\n",
    "    merged_df['data_source'] = data_source_name\n",
    "    \n",
    "    final_df = merged_df[EVENT_COLS]\n",
    "    print(f\"Processed {len(final_df)} OSO transactions.\")\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "281c75af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows imported: 5162837\n",
      "Processed 5734617 OSO transactions.\n"
     ]
    }
   ],
   "source": [
    "address_list_str = stringify_addresses(['dapp_contract', 'trace_contract'], context='oso')\n",
    "\n",
    "query = f\"\"\"\n",
    "  select\n",
    "      format_date('%Y-%m-%d', CAST(date AS DATE)) AS date,\n",
    "      to_address as contract_address,\n",
    "      from_address as user_address,\n",
    "      chain,\n",
    "      sum(transactions) as count_transactions\n",
    "    from `{PROJECT}.static_data_sources.sunny_transactions`\n",
    "    where\n",
    "        to_address in ({address_list_str})\n",
    "        and from_address is not null\n",
    "    group by 1,2,3,4\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "source_name = 'dapp_txns'\n",
    "if REFRESH_OSO:\n",
    "    result = client.query(query)\n",
    "    print(\"Query completed.\")\n",
    "    txns_df = result.to_dataframe()\n",
    "    print(\"Dataframe loaded.\")\n",
    "    txns_df.to_parquet(f'data/raw_metric_data/oso_raw_{source_name}.parquet')\n",
    "else:\n",
    "    txns_df = pd.read_parquet(f'data/raw_metric_data/oso_raw_{source_name}.parquet')\n",
    "    \n",
    "print(\"Rows imported:\", len(txns_df))    \n",
    "\n",
    "EVENT_TABLES.update({\n",
    "    source_name: process_oso_events(txns_df, source_name)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62b19238-4bc7-4918-ab6c-0c5f820b3838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows imported: 983145\n",
      "Processed 982876 OSO transactions.\n"
     ]
    }
   ],
   "source": [
    "other_chains = [\n",
    "    'pending_cyber', 'pending_kroma', 'pending_lisk', 'pending_mint', 'pending_orderly',\n",
    "    'pending_polynomial', 'pending_redstone', 'pending_swanchain'\n",
    "]\n",
    "address_list_str = stringify_addresses(other_chains, context='oso')\n",
    "query = f\"\"\"\n",
    "    select\n",
    "      format_date('%Y-%m-%d', CAST(dt AS DATE)) AS date,\n",
    "      to_address as contract_address,\n",
    "      from_address as user_address,\n",
    "      chain,\n",
    "      count(*) as count_transactions\n",
    "    from `optimism_superchain_raw_onchain_data.transactions`\n",
    "    where\n",
    "        dt between '2024-03-01' and '2024-09-01'\n",
    "        and chain in (\n",
    "          \"cyber\",\"kroma\",\"linea\",\"lisk\",\"lyra\",\n",
    "          \"mint\",\"orderly\",\"polynomial\",\"redstone\",\"swan\"\n",
    "        )\n",
    "        and to_address in ({address_list_str})\n",
    "        and from_address is not null\n",
    "    group by 1,2,3,4\n",
    "\"\"\"\n",
    "\n",
    "source_name = 'new_chain_txns'\n",
    "if REFRESH_OSO:\n",
    "    result = client.query(query)\n",
    "    print(\"Query completed.\")\n",
    "    new_chain_txns_df = result.to_dataframe()\n",
    "    print(\"Dataframe loaded.\")\n",
    "    new_chain_txns_df.to_parquet(f'data/raw_metric_data/oso_raw_{source_name}.parquet')\n",
    "else:\n",
    "    new_chain_txns_df = pd.read_parquet(f'data/raw_metric_data/oso_raw_{source_name}.parquet')\n",
    "\n",
    "print(\"Rows imported:\", len(new_chain_txns_df))    \n",
    "new_chain_txns_df['chain'] = new_chain_txns_df['chain'].apply(\n",
    "    lambda x: x.title() if x != 'swan' else 'SwanChain'\n",
    ")\n",
    "\n",
    "EVENT_TABLES.update({\n",
    "    source_name: process_oso_events(new_chain_txns_df, source_name)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3ad4c1",
   "metadata": {},
   "source": [
    "## Part 3: Get OSO trace events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be375364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows imported: 11857689\n",
      "Processed 11704488 OSO transactions.\n"
     ]
    }
   ],
   "source": [
    "address_list_str = stringify_addresses(['trace_contract', 'factory_contract'], context='oso')\n",
    "\n",
    "query = f\"\"\"\n",
    "    with traces as (\n",
    "      select\n",
    "        format_date('%Y-%m-%d', CAST(block_timestamp AS DATE)) AS date,\n",
    "        transaction_hash,\n",
    "        chain,\n",
    "        to_address as contract_address,\n",
    "        from_address as user_address\n",
    "      from `{PROJECT}.static_data_sources.sunny_traces`\n",
    "        where to_address in ({address_list_str})\n",
    "\n",
    "    union all\n",
    "\n",
    "      select\n",
    "        format_date('%Y-%m-%d', CAST(block_timestamp AS DATE)) AS date,\n",
    "        transaction_hash,\n",
    "        chain,\n",
    "        from_address as contract_address,\n",
    "        to_address as user_address\n",
    "      from `{PROJECT}.static_data_sources.sunny_traces`\n",
    "        where from_address in ({address_list_str})\n",
    "    )\n",
    "\n",
    "    select \n",
    "      date,\n",
    "      chain,\n",
    "      contract_address,\n",
    "      user_address,\n",
    "      approx_count_distinct(transaction_hash) as count_transactions\n",
    "    from traces\n",
    "    group by 1,2,3,4\n",
    "\"\"\"\n",
    "\n",
    "source_name = 'trace_events'\n",
    "if REFRESH_OSO:\n",
    "    result = client.query(query)\n",
    "    print(\"Query completed.\")\n",
    "    traces_df = result.to_dataframe()\n",
    "    print(\"Dataframe loaded.\")\n",
    "    traces_df.to_parquet(f'data/raw_metric_data/oso_raw_{source_name}.parquet')\n",
    "else:\n",
    "    traces_df = pd.read_parquet(f'data/raw_metric_data/oso_raw_{source_name}.parquet')\n",
    "    \n",
    "print(\"Rows imported:\", len(traces_df))    \n",
    "\n",
    "EVENT_TABLES.update({\n",
    "    source_name: process_oso_events(traces_df, source_name)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfe242b",
   "metadata": {},
   "source": [
    "## Part 4. Get metrics for factory contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dbdb82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows imported: 190957\n",
      "Processed 192247 OSO transactions.\n"
     ]
    }
   ],
   "source": [
    "address_list_str = stringify_addresses(['factory_contract'], context='oso')\n",
    "\n",
    "query = f\"\"\"\n",
    "    with factories as (\n",
    "        select distinct\n",
    "          contract_address,\n",
    "          upper(network) as chain,\n",
    "          factory_address\n",
    "        from `{PROJECT}.oso.int_factories`\n",
    "        where (factory_address in ({address_list_str}))\n",
    "    )\n",
    "    select\n",
    "        format_date('%Y-%m-%d', CAST(t.date AS DATE)) AS date,\n",
    "        f.factory_address as contract_address,\n",
    "        t.to_address as deployed_contract_address,\n",
    "        t.from_address as user_address,\n",
    "        t.chain,\n",
    "        sum(t.transactions) as count_transactions\n",
    "    from `{PROJECT}.static_data_sources.sunny_transactions` as t\n",
    "    join factories as f\n",
    "        on t.to_address = f.contract_address\n",
    "        and upper(t.chain) = f.chain\n",
    "    group by 1,2,3,4,5\n",
    "\"\"\"\n",
    "\n",
    "source_name = 'factory_txns'\n",
    "if REFRESH_OSO:\n",
    "    result = client.query(query)\n",
    "    print(\"Query completed.\")\n",
    "    factory_txns_df = result.to_dataframe()\n",
    "    print(\"Dataframe loaded.\")\n",
    "    factory_txns_df.to_parquet(f'data/raw_metric_data/oso_raw_{source_name}.parquet')\n",
    "else:\n",
    "    factory_txns_df = pd.read_parquet(f'data/raw_metric_data/oso_raw_{source_name}.parquet')\n",
    "    \n",
    "print(\"Rows imported:\", len(factory_txns_df))\n",
    "\n",
    "EVENT_TABLES.update({\n",
    "    source_name: process_oso_events(factory_txns_df, source_name)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b99b1524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 9851 OSO transactions.\n"
     ]
    }
   ],
   "source": [
    "factory_deploys_df = (\n",
    "    factory_txns_df\n",
    "    .groupby(['deployed_contract_address', 'contract_address', 'chain'])\n",
    "    ['date']\n",
    "    .min()\n",
    "    .reset_index()\n",
    ")\n",
    "factory_deploys_df.rename(columns={'deployed_contract_address': 'user_address'}, inplace=True)\n",
    "factory_deploys_df['count_transactions'] = 1\n",
    "\n",
    "EVENT_TABLES.update({\n",
    "    'factory_deploys': process_oso_events(factory_deploys_df, 'factory_deploys')\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afef9135",
   "metadata": {},
   "source": [
    "## Part 5. Consolidate and join on Farcaster data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "624d266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "    with profiles as (\n",
    "      select\n",
    "        v.fid,\n",
    "        v.address,\n",
    "        p.custody_address,\n",
    "        json_value(p.data, \"$.username\") as username,\n",
    "      from `{PROJECT}.farcaster.verifications` v\n",
    "      join `{PROJECT}.farcaster.profiles` p\n",
    "        on v.fid = p.fid\n",
    "      where v.deleted_at is null\n",
    "    ),\n",
    "    unioned as (\n",
    "      select\n",
    "        fid,\n",
    "        username,\n",
    "        address\n",
    "      from profiles\n",
    "      where length(address) = 42\n",
    "      union all\n",
    "      select\n",
    "        fid,\n",
    "        username,\n",
    "        custody_address as address\n",
    "      from profiles\n",
    "    )\n",
    "    select distinct\n",
    "      fid,\n",
    "      username,\n",
    "      address\n",
    "    from unioned\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7cc76b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if REFRESH_FARCASTER:\n",
    "    result = client.query(query)\n",
    "    farcaster_df = result.to_dataframe()\n",
    "    farcaster_df.to_parquet('data/raw_metric_data/farcaster.parquet')\n",
    "else:\n",
    "    farcaster_df = pd.read_parquet('data/raw_metric_data/farcaster.parquet')\n",
    "\n",
    "farcaster_df.set_index('address', inplace=True)\n",
    "farcaster_df.dropna(inplace=True)\n",
    "fids = farcaster_df['fid'].to_dict()\n",
    "fusers = farcaster_df['username'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac91df44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>chain</th>\n",
       "      <th>address</th>\n",
       "      <th>contract_type</th>\n",
       "      <th>user_address</th>\n",
       "      <th>date</th>\n",
       "      <th>count_transactions</th>\n",
       "      <th>data_source</th>\n",
       "      <th>farcaster_id</th>\n",
       "      <th>farcaster_username</th>\n",
       "      <th>recipient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23106240</th>\n",
       "      <td>ceac6653-ea1d-43b8-9e02-8329e5ee2a90</td>\n",
       "      <td>Base</td>\n",
       "      <td>0x00000000000052068951aed201da868e29db48ac</td>\n",
       "      <td>factory_contract</td>\n",
       "      <td>0x6ab0a3035943f8932ec0c6fef25655d45715670b</td>\n",
       "      <td>2024-08-29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>factory_deploys</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x3363b291a21cC692A5e07C9C63E3DF45F135EFcd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          uuid chain  \\\n",
       "23106240  ceac6653-ea1d-43b8-9e02-8329e5ee2a90  Base   \n",
       "\n",
       "                                             address     contract_type  \\\n",
       "23106240  0x00000000000052068951aed201da868e29db48ac  factory_contract   \n",
       "\n",
       "                                        user_address        date  \\\n",
       "23106240  0x6ab0a3035943f8932ec0c6fef25655d45715670b  2024-08-29   \n",
       "\n",
       "          count_transactions      data_source  farcaster_id  \\\n",
       "23106240                 1.0  factory_deploys           NaN   \n",
       "\n",
       "         farcaster_username                                   recipient  \n",
       "23106240                NaN  0x3363b291a21cC692A5e07C9C63E3DF45F135EFcd  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([table for table in EVENT_TABLES.values()], axis=0, ignore_index=True)\n",
    "\n",
    "df['farcaster_id'] = df['user_address'].map(fids)\n",
    "df['farcaster_username'] = df['user_address'].map(fusers)\n",
    "df['recipient'] = df['uuid'].map(DF_PROJECTS['recipient'].to_dict())\n",
    "\n",
    "df.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe029ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_source      contract_type     \n",
       "dapp_txns        dapp_contract          4945603\n",
       "                 trace_contract          788935\n",
       "                 factory_contract            79\n",
       "erc20_transfers  trace_contract         1266967\n",
       "factory_deploys  factory_contract          9836\n",
       "                 dapp_contract               15\n",
       "factory_txns     factory_contract        191153\n",
       "                 dapp_contract             1094\n",
       "new_chain_txns   pending_cyber           891563\n",
       "                 pending_kroma            58462\n",
       "                 pending_mint             32205\n",
       "                 pending_swanchain          377\n",
       "                 pending_redstone           255\n",
       "                 pending_polynomial          14\n",
       "token_transfers  token_contract         3215195\n",
       "trace_events     trace_contract        11616736\n",
       "                 dapp_contract            59167\n",
       "                 factory_contract         28585\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('data_source')['contract_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42cd6407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_source\n",
       "trace_events       11704488\n",
       "dapp_txns           5734617\n",
       "token_transfers     3215195\n",
       "erc20_transfers     1266967\n",
       "new_chain_txns       982876\n",
       "factory_txns         192247\n",
       "factory_deploys        9851\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['data_source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47e91484",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"data/raw_metric_data/project_events.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
