{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e923c3aa",
   "metadata": {},
   "source": [
    "# 01 Process Applications\n",
    "\n",
    "Run this notebook to get the latest application data, normalize it, and flag apps with problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d361f10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f320e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "CHAIN_MAPPINGS = json.load(open('data/chains.json', 'r'))\n",
    "CREATOR_CHAINS = ['Base', 'Optimism', 'Zora']\n",
    "\n",
    "EXPORTED_DATA_DIR = \"data/apps/\"\n",
    "RAW_APPS_JSON_PATH = EXPORTED_DATA_DIR + \"applications.json\"\n",
    "REVIEWED_APPS_CSV_PATH = EXPORTED_DATA_DIR + \"applications_reviewed.csv\"\n",
    "\n",
    "PRIMARY_KEY = 'uuid'\n",
    "GROUPER_KEY = 'recipient'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50452819",
   "metadata": {},
   "source": [
    "## Part 1. Fetch application data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db69e940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_application_data(limit, cursor, api_key):\n",
    "    url = f'https://ezrf-impact.vercel.app/api/trpc/projects.list?input=%7B%22json%22%3A%7B%22limit%22%3A{limit}%2C%22cursor%22%3A{cursor}%7D%7D'\n",
    "    headers = {\n",
    "        'content-type': 'application/json',\n",
    "        'round-id': 'the-sunnys',\n",
    "        'x-api-key': api_key\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Data fetched successfully! (Page {cursor})\")\n",
    "        payload = response.json()\n",
    "        json_data = payload['result']['data']['json']\n",
    "        return json_data\n",
    "    else:\n",
    "        print(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
    "\n",
    "        \n",
    "def fetch_all_applications(curs=0, est_apps=2000, lim=200):        \n",
    "    api_key = os.getenv('EZRF_API_KEY')\n",
    "    applications = []\n",
    "    while curs * lim < est_apps:\n",
    "        data = fetch_application_data(lim, curs, api_key)\n",
    "        if data:\n",
    "            applications.extend(data)\n",
    "            curs += 1\n",
    "        if not data or len(data) < lim:\n",
    "            break\n",
    "    print(f\"Total of {len(applications)} applications fetched.\")\n",
    "    return applications\n",
    "\n",
    "def refresh_applications():\n",
    "    applications = fetch_all_applications()\n",
    "    with open(RAW_APPS_JSON_PATH, \"w\") as f:\n",
    "        json.dump(applications, f, indent=2)\n",
    "    print(\"Applications saved to:\", RAW_APPS_JSON_PATH)\n",
    "    \n",
    "def load_applications():\n",
    "    with open(RAW_APPS_JSON_PATH, \"r\") as f:\n",
    "        applications = json.load(f)\n",
    "    print(f\"Total of {len(applications)} applications loaded.\")\n",
    "    return applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7130490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fetched successfully! (Page 0)\n",
      "Data fetched successfully! (Page 1)\n",
      "Data fetched successfully! (Page 2)\n",
      "Data fetched successfully! (Page 3)\n",
      "Data fetched successfully! (Page 4)\n",
      "Data fetched successfully! (Page 5)\n",
      "Data fetched successfully! (Page 6)\n",
      "Data fetched successfully! (Page 7)\n",
      "Data fetched successfully! (Page 8)\n",
      "Total of 1723 applications fetched.\n",
      "Applications saved to: data/apps/applications.json\n",
      "Total of 1723 applications loaded.\n"
     ]
    }
   ],
   "source": [
    "refresh_applications()\n",
    "applications = load_applications()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48417b66",
   "metadata": {},
   "source": [
    "## Part 2. Process and clean application data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1ce623c-5ac5-4fcb-bb6b-7efbe42df948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_address(a):\n",
    "    if not isinstance(a, str):\n",
    "        return None\n",
    "    a = a.lower().strip()\n",
    "    if a[:2] != '0x' or len(a) != 42:\n",
    "        return None\n",
    "    return a\n",
    "\n",
    "def process_application_data(applications):\n",
    "\n",
    "    normalized_data = []\n",
    "    for (i,app) in enumerate(applications):\n",
    "\n",
    "        profile = app.get('profile', {})\n",
    "        if not profile:\n",
    "            profile = {}\n",
    "        profile_name = profile.get('name', '')\n",
    "        metadata = app.get('metadata', {})\n",
    "        awards = metadata.get('sunnyAwards', {})\n",
    "        project_type = awards.get('projectType', '').title()\n",
    "        if project_type == 'Other':\n",
    "            project_type = 'Other Application'\n",
    "        category = awards.get('category', '')\n",
    "        if category == 'Other':\n",
    "            category = 'Other Category'\n",
    "        contracts = awards.get('contracts', [])    \n",
    "\n",
    "        if len(contracts) > 1:\n",
    "            print(\"WARNING: Array encountered at index:\", i)\n",
    "            break\n",
    "        elif len(contracts) == 1:\n",
    "            contract = contracts[0]\n",
    "            address_type = 'contract'\n",
    "            address = contract.get('address')\n",
    "            chain_id = contract.get('chainId')\n",
    "            chain = CHAIN_MAPPINGS.get(str(chain_id), 'All Superchain')\n",
    "        else:\n",
    "            address_type = 'mintingWallet'\n",
    "            address = awards.get('mintingWalletAddress')\n",
    "            chain_id = None\n",
    "            chain = 'All Superchain'\n",
    "        address = clean_address(address)\n",
    "        if not address:\n",
    "            address_type = 'N/A'\n",
    "            chain = None\n",
    "\n",
    "        app_data = {\n",
    "            **awards.get('projectReferences'),\n",
    "            'id': app['id'],\n",
    "            'uuid': app['uuid'],        \n",
    "            'attester': app['attester'],\n",
    "            'recipient': app['recipient'],\n",
    "            'time': app['time'],\n",
    "            'name': app['name'],\n",
    "            'schemaId': app['schemaId'],\n",
    "            'status': app['status'],\n",
    "            'round': app['round'],\n",
    "            'profile_name': profile_name,\n",
    "            'profile_url': f\"https://warpcast.com/{profile_name}\" if profile_name else '',\n",
    "            'profile_image': profile.get('profileImageUrl', ''),\n",
    "            'profile_banner': profile.get('bannerImageUrl', ''),\n",
    "            'metadata_name': metadata.get('name', ''),\n",
    "            'metadata_bio': metadata.get('bio', ''),\n",
    "            'metadata_website': metadata.get('websiteUrl', ''),\n",
    "            'project_type': project_type,\n",
    "            'category': category,\n",
    "            'category_details': awards.get('categoryDetails', ''),\n",
    "            'avatar_url': awards.get('avatarUrl', ''),\n",
    "            'cover_image_url': awards.get('coverImageUrl', ''),\n",
    "            'address_type': address_type,\n",
    "            'address': address,\n",
    "            'chain_id': chain_id,\n",
    "            'chain':  chain,\n",
    "        }\n",
    "        normalized_data.append(app_data)\n",
    "\n",
    "    df = pd.DataFrame(normalized_data)\n",
    "    return df\n",
    "\n",
    "\n",
    "def review_application_dataframe(df):\n",
    "        \n",
    "    # Flag 1: applied as 3 distinct projects from the same Farcaster account\n",
    "    project_count = df.groupby('profile_name')['name'].nunique()\n",
    "    #flagged_farcaster_users = project_count[project_count > 3].index\n",
    "    flagged_farcaster_users = ['kawz']\n",
    "    df['flag_multiple_projects_same_profile'] = df['profile_name'].isin(flagged_farcaster_users)\n",
    "\n",
    "    # Flag 2: applied as an NFT creator category but no valid address\n",
    "    valid_categories_creator = ['Art NFTs', 'Other Media NFTs', 'Community & Curation']\n",
    "    df['flag_creator_no_address'] = (\n",
    "        (df['category'].isin(valid_categories_creator))\n",
    "         & (df['address'].isna())\n",
    "    )\n",
    "\n",
    "    # Flag 3: applied as an app but no address : chain mapping\n",
    "    other_categories_app = ['Channels', 'Frames', 'Other']\n",
    "    df['flag_app_missing_contract'] = (\n",
    "        (~df['category'].isin(valid_categories_creator))\n",
    "        & (~df['category'].isin(other_categories_app))\n",
    "        & (df['address'].isna() | df['chain_id'].isna())\n",
    "    )\n",
    "\n",
    "    # Flag 4: applied as a channel but the url does not conform to the Warpcast channel pattern\n",
    "    df['flag_channel_no_channel'] = (\n",
    "        (df['category'] == 'Channels')\n",
    "        & (df['metadata_website'].str.contains(\"warpcast.com/~/channel/\") == False)\n",
    "    )\n",
    "\n",
    "    # Flag 5: test project with Charmverse in the name :)\n",
    "    df['flag_charmverse_in_name'] = df['name'].str.contains('charmverse', case=False, na=False)\n",
    "\n",
    "    # Flag 6: creator project with the same address claimed by multiple profiles\n",
    "    conflicting_addresses = df[df['project_type'] == 'Creator'].groupby('profile_name')['address'].nunique()\n",
    "    conflicting_addresses = conflicting_addresses[conflicting_addresses>1].index\n",
    "    df['flag_creator_address_conflict'] = (\n",
    "        (df['address'].isin(conflicting_addresses))\n",
    "        & (df['project_type'] == 'Creator')\n",
    "    )\n",
    "    \n",
    "    df['count_flags'] = df[[\n",
    "        'flag_multiple_projects_same_profile', \n",
    "        'flag_creator_no_address', \n",
    "        'flag_app_missing_contract', \n",
    "        'flag_channel_no_channel',\n",
    "        'flag_charmverse_in_name',\n",
    "        'flag_creator_address_conflict'\n",
    "    ]].sum(axis=1)\n",
    "    df['has_flag'] = (df.count_flags > 0).astype(int)\n",
    "    \n",
    "    print(\"Applications processed...\\n\\n\", df['has_flag'].value_counts())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_and_review_apps(applications):\n",
    "    \n",
    "    df_apps = process_application_data(applications)\n",
    "    df = review_application_dataframe(df_apps)\n",
    "    df.drop(columns=[\n",
    "        'attester', 'schemaId', 'round', 'profile_image', 'profile_banner',\n",
    "        'metadata_bio', 'avatar_url', 'cover_image_url', 'category_details'\n",
    "    ], inplace=True)\n",
    "    df.set_index(PRIMARY_KEY, inplace=True)\n",
    "    df.to_csv(REVIEWED_APPS_CSV_PATH)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6c0f1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applications processed...\n",
      "\n",
      " has_flag\n",
      "0    1000\n",
      "1     723\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = process_and_review_apps(applications)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70ea6a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "profile_name\n",
       "kawz    213\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['flag_multiple_projects_same_profile'] == True]['profile_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c46560",
   "metadata": {},
   "source": [
    "## Part 3. Classify valid projects by metric category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "527eb38a-e6aa-47c6-934e-879bd7ab7a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_eligible_apps(df_apps):\n",
    "    \n",
    "    creator_apps = []\n",
    "    project_apps = []\n",
    "    warpcast_apps = []\n",
    "\n",
    "    for primary_key, app in df_apps.iterrows():\n",
    "\n",
    "        app_data = {\n",
    "            PRIMARY_KEY: primary_key,\n",
    "            GROUPER_KEY: app[GROUPER_KEY],\n",
    "            'project_type': app['project_type'],\n",
    "            'category': app['category']\n",
    "        }\n",
    "\n",
    "        if app['has_flag']:\n",
    "            continue\n",
    "\n",
    "        if pd.isna(app['address']):\n",
    "            app_data.update({'website': app['metadata_website']})\n",
    "            warpcast_apps.append(app_data)\n",
    "            continue\n",
    "\n",
    "        app_data.update({\n",
    "            'address': app['address'],\n",
    "            'chain': app['chain']\n",
    "        })\n",
    "\n",
    "        if app['chain'] != 'All Superchain':\n",
    "            project_apps.append(app_data)\n",
    "            continue\n",
    "\n",
    "        for chain in CREATOR_CHAINS:\n",
    "            temp_app_data = app_data.copy()\n",
    "            temp_app_data.update({'chain': chain})\n",
    "            creator_apps.append(temp_app_data)\n",
    "\n",
    "    print(f\"Classified {len(project_apps)} apps as `onchain projects`.\")\n",
    "    pd.DataFrame(project_apps).to_csv(EXPORTED_DATA_DIR + \"project_apps.csv\")\n",
    "    \n",
    "    print(f\"Classified {len(creator_apps) // len(CREATOR_CHAINS)} apps as `creators`.\")\n",
    "    pd.DataFrame(creator_apps).to_csv(EXPORTED_DATA_DIR + \"creator_apps.csv\")\n",
    "    \n",
    "    print(f\"Classified {len(warpcast_apps)} apps as `Warpcast projects`.\")\n",
    "    pd.DataFrame(warpcast_apps).to_csv(EXPORTED_DATA_DIR + \"warpcast_apps.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab31fe70-7353-45d4-a39f-b2cd46c3a20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified 412 apps as `onchain projects`.\n",
      "Classified 525 apps as `creators`.\n",
      "Classified 63 apps as `Warpcast projects`.\n"
     ]
    }
   ],
   "source": [
    "classify_eligible_apps(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e082bba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "has_flag\n",
       "0    552\n",
       "1    440\n",
       "Name: recipient, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('has_flag')['recipient'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a100458",
   "metadata": {},
   "source": [
    "## Part 4. Dump the triage pile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f728a00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533\n"
     ]
    }
   ],
   "source": [
    "df_reject_missing = df[\n",
    "    (df['flag_channel_no_channel'] == 1) \n",
    "    | (df['flag_creator_no_address'] == 1)\n",
    "    | (df['flag_app_missing_contract'] == 1)\n",
    "    & (df['flag_multiple_projects_same_profile'] == 0)\n",
    "    #& (df['status'] == 'pending')\n",
    "]\n",
    "print(len(df_reject_missing))\n",
    "df_reject_missing.to_csv(EXPORTED_DATA_DIR + \"reject_missing_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75576cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n"
     ]
    }
   ],
   "source": [
    "df_reject_spam = df[\n",
    "    (df['flag_multiple_projects_same_profile'] == 1)\n",
    "    | (df['flag_charmverse_in_name'] == 1)\n",
    "    #& (df['status'] == 'pending')\n",
    "]\n",
    "print(len(df_reject_spam))\n",
    "df_reject_spam.to_csv(EXPORTED_DATA_DIR + \"reject_likely_spam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d966804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    }
   ],
   "source": [
    "df_review_flag = df[\n",
    "    (df['has_flag'] == 1)\n",
    "    & (df['status'] == 'approved')\n",
    "]\n",
    "print(len(df_review_flag))\n",
    "df_review_flag.to_csv(EXPORTED_DATA_DIR + \"review_approved_with_flag.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
