import marimo

__generated_with = "0.15.3"
app = marimo.App(width="full")


@app.cell
def setup_pyoso():
    # This code sets up pyoso to be used as a database provider for this notebook
    # This code is autogenerated. Modification could lead to unexpected results :)
    import marimo as mo
    from pyoso import Client
    client = Client()
    try:
        pyoso_db_conn = client.dbapi_connection()    
    except Exception as e:
        pyoso_db_conn = None
    return client, mo


@app.cell
def about_app(mo):
    mo.vstack([
        mo.md("""
        # Stylus SDK Developer Ecosystem
        <small>Author: <span style="background-color: #f0f0f0; padding: 2px 4px; border-radius: 3px;">OSO Team</span> Â· Last Updated: <span style="background-color: #f0f0f0; padding: 2px 4px; border-radius: 3px;">2025-09-25</span></small>
        """),
        mo.md("""
        This dashboard analyzes the growth and impact of the Stylus SDK ecosystem on Arbitrum. It tracks developer engagement, project metrics, and ecosystem expansion through comprehensive data visualization and analysis.
        """),
        mo.accordion({
            "<b>Click to see details on how app was made</b>": mo.accordion({
                "Methodology": """
                - Analyzes developer engagement through fork events and commit activity
                - Uses PageRank algorithm to rank developers by influence and activity
                - Tracks project metrics including active developers, commits, and repository activity
                - Categorizes projects by ecosystem alignment (Stylus, Arbitrum, Solana, EVM)
                - Measures SDK adoption through dependency analysis
                """,
                "Data Sources": """
                - [OSO API](https://docs.opensource.observer/docs/get-started/python) - GitHub metrics and developer activity data
                - [Arbitrum Stylus Collection](https://docs.opensource.observer/docs/get-started/python) - Project and artifact data
                - [Package Dependencies](https://docs.opensource.observer/docs/get-started/python) - SDK usage and adoption metrics
                """,
                "Further Resources": """
                - [Getting Started with Pyoso](https://docs.opensource.observer/docs/get-started/python)
                - [Using the Semantic Layer](https://docs.opensource.observer/docs/get-started/using-semantic-layer)
                - [Marimo Documentation](https://docs.marimo.io/)
                """
            })
        })    
    ])
    return


@app.cell
def process_data(
    dev_pagerank,
    get_devs_who_forked_examples,
    get_metrics_by_developer_ecosystem,
    get_metrics_by_stylus_project,
    get_stylus_sdk_dependents,
    label_repos,
):
    # Get the data
    df_stylus_project_metrics = get_metrics_by_stylus_project()
    df_stylus_sdk_deps = get_stylus_sdk_dependents()
    df_fork_devs = get_devs_who_forked_examples()
    df_ecosystem_metrics = get_metrics_by_developer_ecosystem()

    # Process developer data
    df_fork_devs_labeled = label_repos(df_fork_devs)
    df_fork_devs_ranked = dev_pagerank(df_fork_devs)

    # Create projects summary
    df_projects_from_devs = (
        df_fork_devs_labeled.merge(df_fork_devs_ranked[['dev_id', 'dev_score']], on='dev_id')
        .groupby(['repo_owner', 'project_type'], as_index=False)
        .agg(
            repo_rank=('dev_score', 'sum'),
            first_fork=('first_fork','min'),    
            num_devs=('dev_id', 'nunique'),
            dev_names=('dev_url', lambda x: ' | '.join(sorted(set(x.replace('https://github.com/',''))))),
            repos_worked_on_by_those_devs=('repo_url', lambda x: ' | '.join(sorted(set(x))))
        )
        .sort_values(by=['repo_rank', 'num_devs', 'first_fork'], ascending=[False, False, True])
        .reset_index(drop=True)
        .drop(columns=['repo_rank'])
    )

    # Helper variables
    most_recent_month = df_stylus_project_metrics[df_stylus_project_metrics['metric_name'].str.contains('monthly')==True]['date'].max()
    return (
        df_ecosystem_metrics,
        df_fork_devs_ranked,
        df_projects_from_devs,
        df_stylus_project_metrics,
        df_stylus_sdk_deps,
        most_recent_month,
    )


@app.cell
def generate_stats(
    df_fork_devs_ranked,
    df_projects_from_devs,
    df_stylus_project_metrics,
    df_stylus_sdk_deps,
    mo,
    most_recent_month,
):
    mo.vstack([
        mo.md("## Key Metrics"),
        mo.hstack(
            items=[
                mo.stat(
                    label="Stylus Sprint Projects",
                    bordered=True,
                    value=f"{len(df_stylus_project_metrics['project_name'].unique()):,.0f}",
                    caption="Projects with one or more open source repos"
                ),
                mo.stat(
                    label="SDK Dependents",
                    bordered=True,
                    value=f"{len(df_stylus_sdk_deps):,.0f}",
                    caption="Total repos that import the Stylus SDK"
                ),
                mo.stat(
                    label="Downstream Developers",
                    bordered=True,
                    value=f"{len(df_fork_devs_ranked):,.0f}",
                    caption="Developers using the SDK or who forked one of the examples"
                ),
                mo.stat(
                    label="Developers in Arbitrum Ecosystem",
                    bordered=True,
                    value=f"{len(df_projects_from_devs):,.0f}",
                    caption=f"Total active developers in {most_recent_month.strftime('%B %Y')} (c/o Electric Capital)"
                )
            ],
            widths="equal",
            gap=1
        )
    ])
    return


@app.cell
def _(ECOSYSTEMS, df_ecosystem_metrics, mo, px):
    def make_absolute_fig(dataframe):
        df_pivot = dataframe.pivot(index='date', columns='developer_ecosystem', values='amount')
        df_pivot = df_pivot.reset_index()

        fig = px.line(
            df_pivot, 
            x='date', 
            y=df_pivot.columns[1:],
            color_discrete_map={ECOSYSTEMS[0]: 'black', ECOSYSTEMS[1]: '#AAA', ECOSYSTEMS[2]: '#555'}
        )

        fig.update_layout(
            paper_bgcolor="white",
            plot_bgcolor="white",
            font=dict(size=12, color="#111"),
            margin=dict(t=50, l=20, r=20, b=20),
            legend_title="",
            hovermode="x"
        )
        fig.update_xaxes(
            showgrid=False,
            linecolor="#000",
            ticks="outside",
            tickformat="%b %Y",
            dtick="M6",
            tickangle=-45
        )
        fig.update_yaxes(
            showgrid=True,
            gridcolor="#DDD",
            linecolor="#000",
            ticks="outside",
            rangemode='tozero'
        )
        fig.update_traces(
            hovertemplate="%{y:,.0f}",
            selector=dict(mode='lines')
        )
        return fig

    _fig = make_absolute_fig(df_ecosystem_metrics)
    mo.vstack([
        mo.md("## Absolute Values"),
        mo.ui.plotly(_fig)
    ])
    return


@app.cell
def _(
    MONTHLY_METRICS,
    datetime,
    df_stylus_project_metrics,
    make_joyplot,
    mo,
    most_recent_month,
):
    _num_months = 6
    _start_month = datetime(2025, most_recent_month.month - (_num_months-1), 1).date()
    _stylus_table = (
        df_stylus_project_metrics[
            (df_stylus_project_metrics['metric_name'].str.endswith('monthly') == True) &
            (df_stylus_project_metrics['date'].between(_start_month, most_recent_month)) &
            (df_stylus_project_metrics['amount'].notna())
        ]
        .pivot_table(index='display_name', columns='metric_name', values='amount', aggfunc='sum', fill_value=0)
        .map(lambda x: round(x/_num_months,2))
        [MONTHLY_METRICS]
        .rename(columns={c:clean_metric_name(c) for c in MONTHLY_METRICS})
        .reset_index()
        .rename(columns={'display_name': 'Project'})
    )


    _fig = make_joyplot("GITHUB_commits_weekly")

    stylus_projects = mo.vstack([
        mo.md("### Project Developer Metrics"),
        mo.ui.table(
            data=_stylus_table,
            selection=None,
            show_column_summaries=False,
            show_data_types=False,
            page_size=20
        ),
        mo.md("### Weekly Commits by Project"),
        mo.ui.plotly(_fig)
    ])

    mo.ui.tabs({
        "Stylus Projects": stylus_projects,
        "Alice says": mo.md("Hello, Bob! ðŸ‘‹")
    })

    return


@app.cell
def _(df_stylus_project_metrics, go, np, px):
    def _rgba_from_rgb(rgb, alpha):
        return rgb.replace("rgb", "rgba").replace(")", f",{alpha})")


    def make_joyplot(metric_name):
    
        gap = 1.05
        fill_alpha = 0.35

        df = df_stylus_project_metrics[df_stylus_project_metrics['metric_name'] == metric_name]
        wide = (
            df.pivot_table(index="date", columns="display_name", values="amount", aggfunc="sum")
              .sort_index()
        )

        # Normalize each project by its own max
        denom = wide.max(skipna=True).replace(0, np.nan)
        wide_norm = wide.divide(denom, axis=1)

        # --- CHANGE #1: reverse project order so "A" is at the TOP ---
        cols = list(wide_norm.columns)[::-1]

        # --- CHANGE #2: use only the darker half of the palette, mapped darkestâ†’top to midâ†’bottom ---
        cmap = getattr(px.colors.sequential, 'Greens')
        cmap_subset = cmap[len(cmap)//2:][::-1]  # take darker half, put darkest first

        n = len(cols)
        proj_colors = {}
        for rank, col in enumerate(cols):
            idx = int(round(rank * (len(cmap_subset) - 1) / max(1, n - 1)))
            proj_colors[col] = cmap_subset[idx]

        fig = go.Figure()
        tickvals, ticktext = [], []

        for i, col in enumerate(cols):
            y_offset = i * gap
            y_vals = wide_norm[col].fillna(0).values
            x_vals = wide_norm.index

            color = proj_colors[col]
            fill_color = _rgba_from_rgb(color, fill_alpha)  # your helper

            # Baseline
            fig.add_trace(
                go.Scatter(
                    x=x_vals,
                    y=np.full(y_vals.shape, y_offset, dtype=float),
                    mode="lines",
                    line=dict(width=0),
                    hoverinfo="skip",
                    showlegend=False
                )
            )

            # Ridge
            fig.add_trace(
                go.Scatter(
                    x=x_vals,
                    y=y_vals + y_offset,
                    mode="lines",
                    fill="tonexty",
                    line=dict(color=color, width=1.5),
                    line_shape="spline",
                    fillcolor=fill_color,
                    name=col,
                    customdata=np.c_[wide[col].reindex(x_vals).fillna(0).values],
                    hovertemplate="<b>%{fullData.name}</b><br>Week of: %{x|%d %b %Y}<br>Commits: %{customdata[0]:,.0f}<extra></extra>",
                    showlegend=False
                )
            )

            tickvals.append(y_offset)
            ticktext.append(col)

        fig.update_layout(
            template="plotly_white",
            paper_bgcolor="white",
            plot_bgcolor="white",
            font=dict(size=12, color="#111"),
            margin=dict(l=0, r=80, t=0, b=0),
            showlegend=False,
            title=dict(text="", x=0, xanchor="left", font=dict(size=14, color="#111"))
        )
        fig.update_xaxes(title="", showgrid=False, visible=False, linecolor="#000", linewidth=1)
        fig.update_yaxes(
            title="",
            showgrid=False,
            tickmode="array",
            tickvals=tickvals,
            ticktext=ticktext,
            zeroline=False,
            linecolor="#000",
            linewidth=1,
            tickcolor="#000",
            showline=False
        )
        return fig
    return (make_joyplot,)


@app.cell
def generate_table_sdk_dependents(df_stylus_sdk_deps, mo):
    mo.vstack([
        mo.md("## SDK Dependents"),
        mo.ui.table(
            df_stylus_sdk_deps.reset_index(drop=True),
            selection=None,
            show_column_summaries=False,
            show_data_types=False,
            page_size=50
        )
    ])
    return


@app.cell
def generate_table_projects(df_projects_from_devs, mo):
    mo.vstack([
        mo.md("## Projects by Developer Activity"),
        mo.ui.table(
            df_projects_from_devs.reset_index(drop=True),
            selection=None,
            show_column_summaries=False,
            show_data_types=False,
            page_size=50
        )
    ])
    return


@app.cell
def _(df_stylus_project_metrics):
    df_stylus_project_metrics
    return


@app.cell
def configuration_settings():
    # Configuration constants
    PROJECT_START_DATE = '2024-01-01'
    ECOSYSTEM_START_DATE = '2020-01-01'
    COLLECTION_NAME = 'arb-stylus'
    ECOSYSTEMS = [
        'arbitrum',
        'ethereum_virtual_machine_stack',
        'solana'
    ]
    MONTHLY_METRICS = [
        'GITHUB_active_developers_monthly',
        'GITHUB_full_time_developers_monthly',
        'GITHUB_commits_monthly',    
        'GITHUB_releases_monthly',
        'GITHUB_forks_monthly',
        'GITHUB_stars_monthly',
        'GITHUB_opened_pull_requests_monthly',    
        'GITHUB_merged_pull_requests_monthly',
        'GITHUB_opened_issues_monthly',
        'GITHUB_closed_issues_monthly',
        'GITHUB_project_velocity_monthly',
        'GITHUB_bot_activity_monthly',
    ]
    WEEKLY_METRICS = [
        'GITHUB_commits_weekly',    
        'GITHUB_forks_weekly',
        'GITHUB_stars_weekly',
        'GITHUB_opened_pull_requests_weekly',    
        'GITHUB_merged_pull_requests_weekly',
        'GITHUB_opened_issues_weekly',
        'GITHUB_closed_issues_weekly',
        'GITHUB_project_velocity_weekly',
    ]
    METRIC_NAMES = MONTHLY_METRICS + WEEKLY_METRICS
    return (
        COLLECTION_NAME,
        ECOSYSTEMS,
        ECOSYSTEM_START_DATE,
        METRIC_NAMES,
        MONTHLY_METRICS,
        PROJECT_START_DATE,
    )


@app.cell
def get_data(
    COLLECTION_NAME,
    ECOSYSTEMS,
    ECOSYSTEM_START_DATE,
    METRIC_NAMES,
    PROJECT_START_DATE,
    client,
    pd,
    wraps,
):
    # QUERY HELPERS
    def parse_dates(*cols):
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                df = func(*args, **kwargs)
                for col in cols:
                    if col in df.columns:
                        df[col] = pd.to_datetime(df[col]).dt.date
                return df
            return wrapper
        return decorator

    stringify = lambda arr: "'" + "','".join(arr) + "'"

    # QUERIES
    @parse_dates("date")
    def get_metrics_by_developer_ecosystem():
        return client.to_pandas(f"""
            SELECT
              sample_date AS date,
              projects_v1.display_name AS developer_ecosystem,
              amount
            FROM timeseries_metrics_by_project_v0
            JOIN metrics_v0 USING metric_id
            JOIN projects_v1 USING project_id
            WHERE
              metric_name = 'GITHUB_active_developers_monthly'
              AND sample_date >= DATE '{ECOSYSTEM_START_DATE}'
              AND project_source = 'CRYPTO_ECOSYSTEMS'
              AND project_namespace = 'eco'
              AND project_name IN ({stringify(ECOSYSTEMS)})
            ORDER BY 1,2  
            """)

    @parse_dates("date")
    def get_metrics_by_stylus_project():
        df = client.to_pandas(f"""
            SELECT DISTINCT
              p.display_name AS display_name,
              p.project_name AS project_name,
              m.metric_name AS metric_name,
              ts.sample_date AS date,
              ts.amount AS amount
            FROM metrics_v0 m
            JOIN timeseries_metrics_by_project_v0 ts
              ON m.metric_id = ts.metric_id
            JOIN projects_v1 p
              ON p.project_id = ts.project_id
            JOIN projects_by_collection_v1 pc
              ON p.project_id = pc.project_id
            WHERE
              metric_name IN ({stringify(METRIC_NAMES)})
              AND ts.sample_date >= DATE '{PROJECT_START_DATE}'
              AND pc.collection_name = '{COLLECTION_NAME}'
        """)
        df.dropna(inplace=True)
        return df

    @parse_dates("date")
    def get_metrics_by_stylus_repo():
        return client.to_pandas(f"""
            SELECT
              ap.artifact_name AS artifact_name,
              ap.project_name AS project_name,
              m.metric_name AS metric_name,
              ts.sample_date AS date,
              ts.amount AS amount
            FROM artifacts_by_project_v1 ap
            JOIN projects_by_collection_v1 pc
              ON ap.project_id = pc.project_id
            JOIN timeseries_metrics_by_artifact_v0 ts
              ON ts.artifact_id = ap.artifact_id
            JOIN metrics_v0 m
              ON m.metric_id = ts.metric_id
            WHERE
              pc.collection_name = '{COLLECTION_NAME}'
              AND ap.artifact_source = 'GITHUB'
              AND m.metric_name = 'GITHUB_active_developers_monthly'
              AND ts.sample_date >= DATE '{PROJECT_START_DATE}'
        """)

    def get_stylus_sdk_dependents():
        return client.to_pandas("""
            WITH stylus AS (
              SELECT DISTINCT
                package_artifact_id,
                package_owner_artifact_id
              FROM package_owners_v0
              WHERE
                package_owner_artifact_namespace = 'offchainlabs'
                AND package_owner_artifact_name = 'stylus-sdk-rs'
                AND package_artifact_name = 'stylus-sdk'
            )
            SELECT DISTINCT
              dependent_artifact_id AS artifact_id,
              dependent_artifact_namespace AS repo_owner,
              dependent_artifact_name AS repo_name
            FROM sboms_v0
            JOIN stylus USING package_artifact_id
            WHERE package_owner_artifact_id != dependent_artifact_id
            ORDER BY 1,2
        """)    

    @parse_dates("first_fork")
    def get_devs_who_forked_examples():
        return client.to_pandas(f"""
            WITH stylus AS (
              SELECT DISTINCT package_artifact_id
              FROM package_owners_v0
              WHERE
                package_owner_artifact_namespace = 'offchainlabs'
                AND package_owner_artifact_name = 'stylus-sdk-rs'
                AND package_artifact_name = 'stylus-sdk'
            ),
            example_repos AS (
              SELECT DISTINCT dependent_artifact_id
              FROM sboms_v0
              JOIN stylus USING package_artifact_id
              WHERE dependent_artifact_namespace = 'offchainlabs'
            ),
            devs AS (
              SELECT
                artifact_id AS dev_id,
                artifact_url AS dev_url,
                MIN(time) AS first_fork,
                MIN_BY(to_artifact_id, time) AS forked_repo_id
              FROM int_first_of_event_from_artifact__github AS fe
              JOIN example_repos AS er
                ON fe.to_artifact_id = er.dependent_artifact_id
              JOIN int_github_users AS u
                ON fe.from_artifact_id = u.artifact_id
              WHERE
                event_type = 'FORKED'
                AND time >= DATE '{PROJECT_START_DATE}'
              GROUP BY 1,2
            ),
            dev_events AS (
              SELECT
                devs.dev_id,
                devs.first_fork,
                e.to_artifact_id AS repo_id,
                SUM(e.amount) AS num_commits
              FROM int_events_daily__github AS e
              JOIN devs ON e.from_artifact_id = devs.dev_id
              WHERE
                e.event_type = 'COMMIT_CODE'
                AND e.bucket_day >= devs.first_fork
              GROUP BY 1,2,3
            ),
            star_counts AS (
              SELECT
                de.repo_id,
                APPROX_DISTINCT(e.from_artifact_id) AS star_count
              FROM int_events_daily__github AS e
              JOIN dev_events AS de
                ON e.to_artifact_id = de.repo_id
              WHERE
                e.event_type = 'STARRED'
                AND e.bucket_day >= de.first_fork
                AND e.from_artifact_id != de.dev_id
              GROUP BY 1
            )
            SELECT DISTINCT
              devs.dev_url,
              fr.artifact_url AS first_fork_repo_url,
              a.artifact_url AS repo_url,
              devs.first_fork,
              de.num_commits,
              COALESCE(sc.star_count, 0) AS star_count,          
              a.artifact_namespace AS repo_owner,
              de.dev_id,
              de.repo_id          
            FROM dev_events AS de
            JOIN devs ON de.dev_id = devs.dev_id
            JOIN int_artifacts__github AS a
              ON de.repo_id = a.artifact_id
            LEFT JOIN star_counts AS sc
              ON a.artifact_id = sc.repo_id
            JOIN repositories_v0 AS fr
              ON devs.forked_repo_id = fr.artifact_id
        """)

    def get_repo_alignment_tags(list_of_repo_artifact_ids):
        df = client.to_pandas(f"""
            WITH projects AS (
              SELECT DISTINCT
                artifact_id,
                project_id,
                project_name,
                project_source
              FROM artifacts_by_project_v1
              WHERE
                artifact_id IN ({stringify(list_of_repo_artifact_ids)})
                AND project_source IN ('OSS_DIRECTORY', 'CRYPTO_ECOSYSTEMS')
                AND project_namespace IN ('oso', 'eco')
            ),
            stylus_collection AS (
              SELECT DISTINCT
                project_id,
                True AS in_stylus_collection
              FROM projects_by_collection_v1 AS pbc
              JOIN projects USING project_id
              WHERE pbc.collection_name = '{COLLECTION_NAME}'
            ),
            alignment AS (
              SELECT
                project_id,
                MAX(CASE WHEN project_name = '{ECOSYSTEMS[0]}' THEN True ELSE False END) AS in_{ECOSYSTEMS[0]},
                MAX(CASE WHEN project_name = '{ECOSYSTEMS[1]}' THEN True ELSE False END) AS in_{ECOSYSTEMS[1]},
                MAX(CASE WHEN project_name = '{ECOSYSTEMS[2]}' THEN True ELSE False END) AS in_{ECOSYSTEMS[2]}
              FROM projects
              WHERE project_source = 'CRYPTO_ECOSYSTEMS'
              GROUP BY 1
            )
            SELECT DISTINCT
              projects.artifact_id AS repo_id,
              stylus_collection.*,
              alignment.*
            FROM projects
            LEFT JOIN stylus_collection USING project_id
            LEFT JOIN alignment USING project_id
        """)
        df = df.fillna(False)
        return df

    return (
        get_devs_who_forked_examples,
        get_metrics_by_developer_ecosystem,
        get_metrics_by_stylus_project,
        get_repo_alignment_tags,
        get_stylus_sdk_dependents,
    )


@app.cell
def helper_functions(get_repo_alignment_tags, np, nx, pd):
    def label_repos(df):

        _repos = df['repo_id'].unique()

        df_labeled = get_repo_alignment_tags(_repos)
        df_labeled = df_labeled.groupby('repo_id').max()
        df_labeled["tags"] = df_labeled.apply(lambda row: ";".join([col.replace('in_','') for col in df_labeled.columns if row[col]]), axis=1)
        df_merged = df.set_index('repo_id').join(df_labeled[["tags"]])

        def label_project(tags, dev_url, repo_url):
            if not isinstance(tags, str):
                tags = ''
            if 'stylus' in tags:
                return 'Project (Stylus Sprint)'
            if '/offchainlabs/' in repo_url:
                return 'Offchain Labs'
            if 'solana' in tags:
                if ';' in tags:
                    return 'Project (EVM + Solana Ecosystems)'
                else:
                    return 'Project (Solana Ecosystem)'
            if 'arbitrum' in tags:
                return 'Project (Arbitrum Ecosystem)'
            if len(tags) > 1:
                return 'Project (EVM Ecosystem)'
            if dev_url in repo_url:
                return 'Personal'
            return 'Project (Other)'

        df_merged['project_type'] = df_merged.apply(lambda x: label_project(x['tags'], x['dev_url'], x['repo_url']), axis=1)
        df_merged.drop(columns="tags", inplace=True)

        return df_merged



    def dev_pagerank(
        df,
        alpha=0.85,
        max_iter=100,
        star_exp=1.0,        # how strongly repo stars matter
        commit_exp=1.0,      # how strongly commit volume matters
        star_floor=0.0       # add to stars to avoid zero-sinks; e.g., 1.0
    ):

        # Nodes
        devs = df[['dev_id','dev_url']].drop_duplicates().reset_index(drop=True)
        repos = df[['repo_url','star_count']].drop_duplicates().reset_index(drop=True)

        G = nx.DiGraph()
        for _, r in devs.iterrows():
            G.add_node(("dev", r.dev_id), url=r.dev_url, ntype="dev")
        for _, r in repos.iterrows():
            stars = float(r.star_count or 0.0)
            G.add_node(("repo", r.repo_url), stars=stars, ntype="repo")

        # Edges (commit-weighted devâ†’repo, star-weighted repoâ†’dev)
        for _, r in df.iterrows():
            d = ("dev", r.dev_id); rep = ("repo", r.repo_url)
            if d not in G or rep not in G: 
                continue

            c = max(0.0, float(r.num_commits or 0.0))
            s = max(0.0, float(r.star_count  or 0.0))
            w_dr = c**commit_exp
            w_rd = (s + star_floor)**star_exp

            if w_dr > 0: G.add_edge(d,   rep, weight=w_dr)
            if w_rd > 0: G.add_edge(rep, d,   weight=w_rd)

        # Personalization: devs by commits, repos by stars
        dev_commit_sum = df.groupby("dev_id")["num_commits"].sum().reindex(devs.dev_id).fillna(0)
        repo_stars     = repos.set_index("repo_url")["star_count"].fillna(0)

        p = {}
        for n in G.nodes:
            ntype, key = n
            if ntype == "dev":
                p[n] = 1.0 + np.log1p(float(dev_commit_sum.get(key, 0.0)))
            else:
                p[n] = 1.0 + np.log1p(float(repo_stars.get(key, 0.0)) + star_floor)

        z = sum(p.values()) or 1.0
        p = {k:v/z for k,v in p.items()}

        pr = nx.pagerank(G, alpha=alpha, personalization=p, weight="weight", max_iter=max_iter)
        rows = []
        for (ntype, key), score in pr.items():
            if ntype != "dev": 
                continue
            rows.append({
                "dev_id": key,
                "dev_score": score,
                "dev_url": G.nodes[(ntype,key)]["url"]
            })
        dev_rank = pd.DataFrame(rows).sort_values("dev_score", ascending=False, kind="mergesort").reset_index(drop=True)

        # Helpful diagnostics
        dev_rank = dev_rank.merge(
            devs.assign(total_commits=dev_commit_sum.values), on=["dev_id","dev_url"], how="left"
        )
        repo_star_map = repos.set_index("repo_url")["star_count"].to_dict()
        exposure = (
            df.assign(w=lambda x: (x["num_commits"].clip(lower=0).astype(float)**commit_exp) 
             * (df["repo_url"].map(repo_star_map).fillna(0).astype(float)))
              .groupby("dev_id")["w"]
              .sum()
              .rename("star_exposure")
        )
        dev_rank = dev_rank.merge(exposure, on="dev_id", how="left").fillna({"star_exposure":0.0})

        return dev_rank    
    return dev_pagerank, label_repos


@app.cell
def import_libraries():
    from datetime import datetime, date, timedelta
    from functools import wraps
    import pandas as pd
    import plotly.graph_objects as go
    import plotly.express as px
    import networkx as nx
    import numpy as np
    return datetime, go, np, nx, pd, px, wraps


@app.function
def clean_metric_name(col):
    return col.replace('GITHUB_','').replace('_monthly','').replace('_',' ').title()


if __name__ == "__main__":
    app.run()
