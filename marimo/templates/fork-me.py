import marimo

__generated_with = "0.16.2"
app = marimo.App(width="medium")


@app.cell
def setup_pyoso():
    # This code sets up pyoso to be used as a database provider for this notebook
    # This code is autogenerated. Modification could lead to unexpected results :)
    import marimo as mo
    from pyoso import Client
    client = Client()
    try:
        pyoso_db_conn = client.dbapi_connection()    
    except Exception as e:
        pyoso_db_conn = None
    return client, mo


@app.cell
def about_app(mo):
    mo.vstack([
        mo.md("""
        # Fork Me: Getting Started with OSO Data
        <small>Author: <span style="background-color: #f0f0f0; padding: 2px 4px; border-radius: 3px;">OSO Team</span> Â· Last Updated: <span style="background-color: #f0f0f0; padding: 2px 4px; border-radius: 3px;">2025-10-12</span></small>
        """),
        mo.md("""
        Welcome to this interactive tutorial! This notebook will teach you the fundamental patterns for working with OSO data. You'll learn how to query projects, filter data interactively, and create visualizations.

        **What you'll learn:**

        - How to query projects from the OSS Directory
        - How to fetch and filter timeseries metrics
        - How to create interactive dashboards with stats, tables, and charts

        Feel free to fork this notebook and experiment with the code!
        """),
        mo.accordion({
            "<b>Query Patterns</b>": """
            **Understanding OSO Data Structure**

            The OSO database has several key tables you'll use frequently:

            - `projects_v1` - Contains project metadata (names, sources, namespaces)
            - `timeseries_metrics_by_project_v0` - Time-series metrics data (the "fact table")
            - `metrics_v0` - Metric definitions and names

            **Common JOIN Pattern:**
            ```sql
            SELECT 
              sample_date,
              projects_v1.display_name,
              metrics_v0.metric_name,
              timeseries_metrics_by_project_v0.amount
            FROM timeseries_metrics_by_project_v0
            JOIN metrics_v0 USING (metric_id)
            JOIN projects_v1 USING (project_id)
            WHERE project_source = 'OSS_DIRECTORY'
              AND metric_name IN ('GITHUB_active_developers_monthly', ...)
            ```

            This pattern joins the fact table with dimension tables to get human-readable names and filter by specific metrics.
            """,
            "<b>Interactive Filtering</b>": """
            **Post-Query vs Pre-Query Filtering**

            There are two approaches to filtering data:

            1. **Pre-Query Filtering (SQL):**
               - Filter in the WHERE clause
               - Returns less data from database
               - Best for: large datasets, single fixed view

            2. **Post-Query Filtering (Pandas):**
               - Query all data once, filter in Python
               - Enables instant interactivity with UI controls
               - Best for: smaller datasets, multiple filter combinations

            This notebook demonstrates post-query filtering. We'll query data for the last 12 months and multiple metrics, then filter based on your UI selections. This approach makes the dashboard feel responsive without re-querying the database.
            """,
            "<b>Visualization Basics</b>": """
            **Marimo UI Components**

            Marimo provides several components for building dashboards:

            - `mo.stat()` - Display key metrics with labels
            - `mo.ui.table()` - Interactive tables with formatting
            - `mo.ui.plotly()` - Interactive Plotly charts
            - `mo.ui.dropdown()`, `mo.ui.date()` - Input controls
            - `mo.hstack()`, `mo.vstack()` - Layout containers

            These components are reactive: when an input changes, all dependent cells automatically re-execute. This makes it easy to build interactive dashboards without writing callback functions.
            """
        })    
    ])
    return


@app.cell
def import_libraries():
    import pandas as pd
    import plotly.express as px
    import plotly.graph_objects as go
    from datetime import date, timedelta
    return date, go, pd, px, timedelta


@app.cell
def explain_configuration(mo):
    mo.md(
        """
    ## Step 1: Configure Your Analysis

    We'll start by setting up interactive controls. These let you filter the data after it's been queried from the database.

    **The controls:**

    - **Date Range**: Filter metrics to a specific time period
    - **Projects**: Select which projects to analyze and compare
    - **Metric**: Choose what aspect of project activity to measure

    **Pattern to remember:**
    ```python
    metric_input = mo.ui.dropdown(
        options=['Active Developers', 'Commits', 'Stars'],
        value='Active Developers',
        label='Choose a metric'
    )
    ```

    The `value` parameter sets the default selection. Try changing the controls below to see how the data updates!
    """
    )
    return


@app.cell
def configuration_settings(date, mo, timedelta):
    # Calculate default dates: 12 months ago to today
    _end_date_default = date.today()
    _start_date_default = _end_date_default - timedelta(days=365)

    start_date_input = mo.ui.date(
        label="Start Date",
        value=_start_date_default
    )

    end_date_input = mo.ui.date(
        label="End Date", 
        value=_end_date_default
    )

    # We'll populate project options after querying the database
    # For now, create a placeholder that will be updated
    metric_input = mo.ui.dropdown(
        options={
            'Active Developers': 'GITHUB_active_developers_monthly',
            'Commits': 'GITHUB_commits_monthly',
            'Stars': 'GITHUB_stars_monthly'
        },
        value='Active Developers',
        label='Choose a Metric',
        full_width=True
    )

    mo.vstack([
        mo.hstack([start_date_input, end_date_input], widths="equal", gap=1),
        metric_input
    ])
    return end_date_input, metric_input, start_date_input


@app.cell
def explain_projects_query(mo):
    mo.md(
        """
    ## Step 2: Query Projects from OSS Directory

    First, we need to get a list of projects from the OSS Directory. This query demonstrates a simple pattern for filtering projects.

    **The Query Pattern:**
    ```sql
    SELECT 
      project_id, 
      display_name, 
      star_count
    FROM projects_v1
    JOIN key_metrics_by_project_v0 USING (project_id)
    JOIN metrics_v0 USING (metric_id)
    WHERE project_source = 'OSS_DIRECTORY'
      AND project_namespace = 'oso'
      AND metric_name = 'GITHUB_stars_over_all_time'
      AND amount >= 1000
    ```

    **What this does:**

    - `project_source = 'OSS_DIRECTORY'` filters to OSS Directory projects
    - `project_namespace = 'oso'` gets the main OSO curated collection
    - We join with metrics to filter by star count (â‰¥1000 stars)
    - This gives us a reasonable set of well-known projects to analyze
    """
    )
    return


@app.cell
def get_projects_list(client):
    _query = """
    SELECT DISTINCT
      p.project_id,
      p.display_name,
      km.amount AS star_count
    FROM key_metrics_by_project_v0 AS km
    JOIN projects_v1 AS p ON p.project_id = km.project_id
    JOIN metrics_v0 AS m ON km.metric_id = m.metric_id
    WHERE
      p.project_source = 'OSS_DIRECTORY'
      AND p.project_namespace = 'oso'
      AND m.metric_name = 'GITHUB_stars_over_all_time'
      AND km.amount >= 1000
    ORDER BY
      km.amount DESC
    LIMIT 15
    """

    df_projects = client.to_pandas(_query)
    return (df_projects,)


@app.cell
def create_project_selector(df_projects, mo):
    # Now that we have projects, create the multiselect control
    _project_options = dict(zip(df_projects['display_name'], df_projects['project_id']))

    # Default to top 3 projects
    _default_projects = list(_project_options.keys())[:3]

    project_input = mo.ui.multiselect(
        options=_project_options,
        value=_default_projects,
        label='Select Projects to Compare',
        full_width=True
    )

    project_input
    return (project_input,)


@app.cell
def explain_metrics_query(mo):
    mo.md(
        """
    ## Step 3: Query Timeseries Metrics

    Now we'll query the main metrics data. This demonstrates a common pattern: joining three tables to get timeseries data.

    **The Query Pattern:**
    ```sql
    SELECT
      sample_date,
      projects_v1.display_name AS project_name,
      metrics_v0.metric_name,
      timeseries_metrics_by_project_v0.amount
    FROM timeseries_metrics_by_project_v0       -- The fact table
    JOIN metrics_v0 USING (metric_id)           -- Get metric names
    JOIN projects_v1 USING (project_id)         -- Get project names
    WHERE metric_name IN (...)                  -- Filter to metrics we want
      AND sample_date >= DATE(...)              -- Filter to date range
      AND project_id IN (...)                   -- Filter to selected projects
    ```

    **Why this approach?**

    We query broadly (12 months of data, multiple metrics) and filter in pandas later. This gives us flexibility:

    - UI controls update instantly without re-querying
    - You can switch between metrics without waiting
    - The database query runs only once

    For very large datasets, you'd filter in SQL instead. But for this tutorial, post-query filtering provides a better learning experience.
    """
    )
    return


@app.cell
def get_data(client, df_projects, pd):
    # Get list of project IDs to query
    _project_ids = df_projects['project_id'].tolist()
    _project_ids_str = "'" + "','".join(_project_ids) + "'"

    _query = f"""
    SELECT
      ts.sample_date,
      p.project_id,
      p.display_name AS project_name,
      m.metric_name,
      ts.amount
    FROM timeseries_metrics_by_project_v0 AS ts
    JOIN metrics_v0 AS m ON ts.metric_id = m.metric_id
    JOIN projects_v1 AS p ON ts.project_id = p.project_id
    WHERE 
      -- Filter to the metrics we want to analyze
      m.metric_name IN (
        'GITHUB_active_developers_monthly',
        'GITHUB_commits_monthly',
        'GITHUB_stars_monthly'
      )
      -- Get the last 12 months of data
      AND ts.sample_date >= DATE_ADD('month', -12, CURRENT_DATE)
      AND ts.sample_date < DATE_TRUNC('month', CURRENT_DATE)
      -- Filter to our selected projects
      AND p.project_id IN ({_project_ids_str})
    ORDER BY 
      ts.sample_date, 
      p.display_name, 
      m.metric_name
    """

    df_raw = client.to_pandas(_query)
    # Convert sample_date to datetime for filtering
    df_raw['sample_date'] = pd.to_datetime(df_raw['sample_date'])
    return (df_raw,)


@app.cell
def explain_filtering(mo):
    mo.md(
        """
    ## Step 4: Filter Data with Pandas

    Post-query filtering means we query all data once, then filter it using pandas based on UI inputs.

    **The Filtering Pattern:**
    ```python
    df_filtered = df_raw[
        (df_raw['sample_date'] >= start_date) &
        (df_raw['sample_date'] <= end_date) &
        (df_raw['project_id'].isin(selected_projects)) &
        (df_raw['metric_name'] == selected_metric)
    ]
    ```

    **When to use this approach:**

    - âœ… Dataset is small enough to load into memory
    - âœ… You want instant UI updates without re-querying
    - âœ… Users will try many different filter combinations
    - âœ… The query is fast enough to run once upfront

    **When to use SQL filtering instead:**

    - âŒ Dataset is very large (millions of rows)
    - âŒ Query is slow and you need to reduce data volume
    - âŒ You're building a production dashboard with complex filters

    In this tutorial, we're working with a manageable dataset (15 projects Ã— 12 months Ã— 3 metrics = ~540 rows), so post-query filtering works great!
    """
    )
    return


@app.cell
def filter_data_post_query(
    df_raw,
    end_date_input,
    metric_input,
    mo,
    pd,
    project_input,
    start_date_input,
):
    # Validate inputs
    if not project_input.value or len(project_input.value) == 0:
        mo.stop(True, mo.md("âš ï¸ Please select at least one project to analyze."))

    # Convert date inputs to datetime for comparison
    _start_date = pd.to_datetime(start_date_input.value)
    _end_date = pd.to_datetime(end_date_input.value)

    # Validate date range
    if _start_date >= _end_date:
        mo.stop(True, mo.md("âš ï¸ Start date must be before end date."))

    # Get selected project IDs
    _selected_projects = project_input.value

    # Get selected metric name (the value from the dropdown maps display name to metric_name)
    _selected_metric = metric_input.value

    # Filter the data
    df_filtered = df_raw[
        (df_raw['sample_date'] >= _start_date) &
        (df_raw['sample_date'] <= _end_date) &
        (df_raw['project_id'].isin(_selected_projects)) &
        (df_raw['metric_name'] == _selected_metric)
    ].copy()
    return (df_filtered,)


@app.cell
def explain_stats(mo):
    mo.md(
        """
    ## Step 5: Display Summary Statistics

    Stats are simple widgets that display key metrics. They're great for summary information that helps users understand the data at a glance.

    **The Pattern:**
    ```python
    my_stat = mo.stat(
        label='Total Projects',
        value='42',
        bordered=True,
        caption='Optional description'
    )
    ```

    **Best practices:**

    - Use clear, concise labels
    - Format numbers appropriately (commas for thousands, % for percentages)
    - Optionally add captions for context
    - Arrange multiple stats horizontally with `mo.hstack()`

    We'll calculate three metrics from the filtered data to give you an overview of what you've selected.
    """
    )
    return


@app.cell
def generate_stats(df_filtered, metric_input, mo):
    # Stat 1: Total projects selected
    _total_projects = df_filtered['project_name'].nunique()

    # Stat 2: Average metric value across the entire period
    _avg_value = df_filtered['amount'].mean() if len(df_filtered) > 0 else 0

    # Stat 3: Growth % (latest month vs earliest month)
    if len(df_filtered) > 0:
        # Group by date and sum across all projects
        _by_date = df_filtered.groupby('sample_date')['amount'].sum().sort_index()
        if len(_by_date) >= 2:
            _first_val = _by_date.iloc[0]
            _last_val = _by_date.iloc[-1]
            _growth_pct = ((_last_val - _first_val) / _first_val * 100) if _first_val > 0 else 0
        else:
            _growth_pct = 0
    else:
        _growth_pct = 0

    # Get the display name for the metric (create reverse mapping)
    _metric_names_reverse = {v: k for k, v in metric_input.options.items()}
    _metric_display = _metric_names_reverse.get(metric_input.value, 'Unknown')

    _stat1 = mo.stat(
        label="Projects Selected",
        bordered=True,
        value=f"{_total_projects:,}",
        caption="From OSS Directory"
    )

    _stat2 = mo.stat(
        label=f"Avg. {_metric_display}",
        bordered=True,
        value=f"{_avg_value:,.1f}",
        caption="Per project per month"
    )

    _stat3 = mo.stat(
        label="Growth Rate",
        bordered=True,
        value=f"{_growth_pct:+.1f}%",
        caption="First to last month"
    )

    mo.vstack([
        mo.md("### Summary Statistics"),
        mo.hstack([_stat1, _stat2, _stat3], widths="equal", gap=1)
    ])
    return


@app.cell
def explain_table(mo):
    mo.md(
        """
    ## Step 6: Create an Interactive Table

    Tables are useful for detailed comparisons. They let users see the exact numbers and sort/search through the data.

    **The Pattern:**
    ```python
    mo.ui.table(
        data=df,
        format_mapping={'Amount': '{:,.0f}'},  # Format with commas
        page_size=10,
        selection=None  # Disable row selection
    )
    ```

    **Formatting options:**

    - `'{:,.0f}'` - Thousands separator, no decimals
    - `'{:,.2f}'` - Thousands separator, 2 decimals
    - `'{:.1%}'` - Percentage with 1 decimal

    We'll create a leaderboard showing which projects have the highest values for the selected metric.
    """
    )
    return


@app.cell
def generate_table(df_filtered, mo):
    # Calculate totals and averages per project
    _table_data = (
        df_filtered
        .groupby('project_name')
        .agg(
            total=('amount', 'sum'),
            average=('amount', 'mean'),
            months=('sample_date', 'nunique')
        )
        .sort_values('total', ascending=False)
        .reset_index()        
        .rename(columns={
            'project_name': 'Project',
            'total': 'Total',
            'average': 'Avg per Month',
            'months': 'Months'
        })
    )

    mo.vstack([
        mo.md("### Project Leaderboard"),
        mo.ui.table(
            _table_data,
            format_mapping={
                'Total': '{:,.0f}',
                'Avg per Month': '{:,.1f}'
            },
            page_size=10,
            selection=None,
            show_column_summaries=False
        )
    ])
    return


@app.cell
def explain_chart(mo):
    mo.md(
        """
    ## Step 7: Visualize Trends with Charts

    Charts help visualize trends over time and make it easy to compare projects at a glance.

    **The Pattern:**
    ```python
    fig = px.line(
        df, 
        x='date', 
        y='value', 
        color='project',
        title='My Chart'
    )

    fig.update_layout(
        paper_bgcolor='white',
        plot_bgcolor='white',
        # ... more styling
    )

    mo.ui.plotly(fig)
    ```

    **Key styling choices:**

    - White background for a clean look
    - Grid lines for easier reading
    - Custom hover templates for clear data display
    - Appropriate color schemes (one color per project)

    The chart below shows how your selected metric changes over time for each project.
    """
    )
    return


@app.cell
def generate_plot(df_filtered, go, metric_input, mo, px):
    # Get the display name for the metric (create reverse mapping)
    _metric_names_reverse = {v: k for k, v in metric_input.options.items()}
    _metric_display = _metric_names_reverse.get(metric_input.value, 'Unknown')

    def _make_fig(dataframe, title=""):
        if len(dataframe) == 0:
            # Create empty figure with message
            fig = go.Figure()
            fig.update_layout(
                paper_bgcolor="white",
                plot_bgcolor="white",
                font=dict(size=12, color="#111"),
                title=dict(text=f'<b>{title}</b>', x=0, xanchor="left"),
                margin=dict(t=50, l=20, r=20, b=20),
                annotations=[dict(
                    x=0.5, y=0.5,
                    xref="paper", yref="paper",
                    text="No data available for the selected filters",
                    showarrow=False,
                    font=dict(size=14, color="#666")
                )]
            )
            return fig

        fig = px.line(
            dataframe,
            x='sample_date',
            y='amount',
            color='project_name',
            title=f'<b>{title}</b>',
            labels={
                'sample_date': 'Date',
                'amount': title,
                'project_name': 'Project'
            }
        )

        fig.update_layout(
            paper_bgcolor="white",
            plot_bgcolor="white",
            font=dict(size=12, color="#111"),
            title=dict(text=f'<b>{title}</b>', x=0, xanchor="left"),
            margin=dict(t=50, l=20, r=20, b=20),
            legend_title="Project",
            hovermode="x unified"
        )

        fig.update_xaxes(
            showgrid=False,
            linecolor="#000",
            ticks="outside",
            tickformat="%b %Y"
        )

        fig.update_yaxes(
            showgrid=True,
            gridcolor="#DDD",
            linecolor="#000",
            ticks="outside",
            rangemode='tozero'
        )

        fig.update_traces(
            hovertemplate="%{y:,.0f}",
            line=dict(width=2)
        )

        return fig

    _fig = _make_fig(df_filtered, f"{_metric_display} Over Time")

    mo.vstack([
        mo.md("### Time Series Visualization"),
        mo.ui.plotly(_fig)
    ])
    return


@app.cell
def display_tutorial_tips(mo):
    mo.md(
        """
    ## ðŸŽ¯ Try It Yourself!

    - **Change the date range** to see how post-query filtering works instantly. Notice how the stats, table, and chart all update without re-querying the database!

    - **Select different projects** to compare their metrics. Try selecting projects with very different characteristics (e.g., large vs small, frontend vs infrastructure).

    - **Switch between metrics** using the dropdown to see different aspects of project activity. How do the patterns differ between developers, commits, and stars?

    ## ðŸš€ Next Steps

    Now that you understand the basics, here are some ways to extend your learning:

    1. **Fork this notebook** and modify the queries to explore different metrics
    2. **Read the [Pyoso documentation](https://docs.opensource.observer/docs/get-started/python)** to learn about more advanced queries
    3. **Explore other notebooks** in the `marimo/` directory to see different visualization techniques
    4. **Visit the [OSS Directory](https://github.com/opensource-observer/oss-directory)** to add your own projects

    **Questions or feedback?** Join the [OSO Discord](https://www.opensource.observer/discord) or open an issue on GitHub.

    Happy exploring! ðŸŽ‰
    """
    )
    return


@app.cell
def _():
    return


if __name__ == "__main__":
    app.run()
